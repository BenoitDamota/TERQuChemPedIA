\subsubsection{Fonctions de coût}

\par Afin d'évaluer la qualité des prédictions et pour guider les modèles lors de la procédure d'optimisation des poids (REF DEEP LEARNING), nous devons définir une fonction de coût. Pour chaque prédiction évaluée, celle-ci doit renvoyer une valeur évaluant sa qualité. Par définition, plus la prédiction est bonne et plus le coût associé doit être faible. Pour évaluer la sortie des modèles qui est constituée de multiples valeurs, nous utilisons la métrique \emph{Root Mean Square Error} (RMSE). Celle-ci consiste à calculer la moyenne du carrés des erreurs (différence entre le vecteur prédit et le vecteur attendu), puis à appliquer une racine carrée pour remettre le résultat dans l'ordre de grandeur des données d'entrée.\\

\par Ce RMSE (que l'on qualifie de total) est toutefois trop simpliste pour nos modèles car il considère toutes les valeurs du vecteur bruit prédit, alors que certaines valeurs correspondant à des atomes non définis en entrée doivent être ignorées (REF HOMOGEN TAILLE DONNEES). C'est pourquoi nous définissons une métrique que l'on nomme RMSE partiel et qui utilise un masque pour ne calculer le RMSE que sur les valeurs prédites correspondant à des valeurs non nulles en entrée.\\
Sans l'utilisation du RMSE partiel, les résultats d'évaluation des modèles seraient trompeurs à cause du fait que la plupart des vecteurs cibles (bruit à prédire) contiennent de nombreux zéros du fait de la nécessité d'avoir des entrées et sorties de taille fixe (REF HOMOGEN TAILLE DONNEES) et de la distribution des tailles de molécules (REF DONNEES TAILLES MOL). En effet, le RMSE total évaluerait en grande partie la capacité des modèles à prédire des valeurs nulles, ce qui constitue une tâche très simple et éloignée de nos objectifs.

\par Si tous les modèles ont été entraînés avec le RMSE partiel comme fonction de coût, un des modèles (voir table des paramètres en annexe) a été entraîné une seconde fois avec le RMSE total comme fonction de coût. Cela avait pour but de tester si le changement de fonction de coût le guidait vers de meilleures solutions. Toutefois, afin d'avoir une mesure objective des performances, l'opposé du RMSE partiel était alors utilisé comme fonction de validation.

\subsubsection{Fonctions de validation}

\par En plus des fonctions de coût qui permettent de guider les modèles vers de bonnes solutions lors de l'entraînement, nous utilisons deux fonctions de validation qui ont pour objectif d'évaluer les performances des modèles sur les jeux de test (REF DONNEES JEUX TEST). Les premiers modèles utilisaient le score R2\footnote{\url{https://en.wikipedia.org/wiki/Coefficient_of_determination}}, défini comme le quotient de la somme du carré des erreurs par la somme du carré de l'écart des valeurs cibles à la moyenne. Le score R2 a peu à peu été abandonné au profit de l'opposé du RMSE partiel, notamment dans le but d'uniformiser l'évaluation des modèles entre leur entraînement et leur test sur des données inconnues.

\subsubsection{Erreur introduite par le bruit}

\par Afin d'évaluer les bénéfices des prédictions des modèles par rapport aux données géométriques bruitées, nous calculons le RMSE (REF FONCT COUT) des données bruitées. Formellement, nous calculons la moyenne des RMSE partiels des vecteurs bruit sur tout le jeu de données. Cela nous donne une idée précise de l'erreur introduite par le bruit. Tout modèle possédant un RMSE partiel inférieur à cette valeur sur le jeu de test aura donc prédit une partie du bruit et mené à une amélioration de la géométrie. Le RMSE du bruit introduit « faible » est d'environ 2,8 pm et celui du bruit « fort » est de 17,2 pm (REF BRUITS).	