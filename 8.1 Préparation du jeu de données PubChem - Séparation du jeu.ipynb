{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation du jeu\n",
    "\n",
    "L'objectif de ce notebook est de séparer le jeu de données en un jeu d'entraînement (90% des données) et un jeu de validation (10% des données).\n",
    "Le code de ce notebook sera extrait et exécuté sur la machine Tesla afin de profiter du CPU et de la mémoire disponible pour créer deux nouveaux fichiers h5 tout en gardant le dataset original en mémoire et intact.\n",
    "La séparation du jeu en fichiers distincts permettra de s'assurer facilement par la suite que l'on s'entraîne uniquement sur le jeu d'entraînement et qu'on ne voit jamais les données de validation avant la phase de test\n",
    "\n",
    "Une fois le jeu séparé en un jeu d'entraînement et un jeu de validation, on créé un sous ensemble du jeu d'entraînement sur lequel on va pouvoir par la suite faire les tests d'entraînement de modèles avant de lancer l'entraînement des modèles sur l'ensemble d'un jeu d'entraînement.\n",
    "\n",
    "### Définition des constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_filename = \"../data/riken_v2_reduced.h5\"\n",
    "train_dataset_filename = \"../data/train_set_riken_v2_reduced.h5\"\n",
    "test_dataset_filename = \"../data/test_set_riken_v2_reduced.h5\"\n",
    "minimal_dataset_filename = \"../data/minimal_set_riken_v2_reduced.h5\"\n",
    "test_size = 0.1\n",
    "minimal_dataset_size = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation jeu d'entraînement/jeu de test\n",
    "\n",
    "#### Définition de la fonction de séparation du jeu original en un jeu d'entraînement et un jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etudiant/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def split_jeux(original_dataset_filename, train_dataset_filename, test_dataset_filename, test_size=0.1):\n",
    "    \"\"\" Fonction prenant un dataset h5 en entrée et le séparant en un jeu d'entraînement et un jeu de test,\n",
    "    qu'elle enregistre\"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # On charge le jeu de données original (en lecture seule)\n",
    "    original_dataset = h5py.File(original_dataset_filename, 'r')  \n",
    "\n",
    "    # On créé un tableau numpy contenant toutes les données\n",
    "    print(\"Loading the data...\")\n",
    "    data = np.array([np.int32(original_dataset[\"pubchem_id\"]), \n",
    "              np.asarray(original_dataset[\"anums\"]),\n",
    "              np.asarray(original_dataset[\"amasses\"]),\n",
    "              np.asarray(original_dataset[\"riken_coords\"])]).T\n",
    "    \n",
    "    # On fait appel à scikit learn pour séparer les données de façon aléatoire\n",
    "    print(\"Separation of the data...\")\n",
    "    train_set, test_set = train_test_split(data, test_size=test_size, random_state = 12)\n",
    "    \n",
    "    \n",
    "    # On créé deux fichiers h5\n",
    "    print(\"Creating h5 files...\")\n",
    "    train_set_h5 = h5py.File(train_dataset_filename, 'w')\n",
    "    test_set_h5 = h5py.File(test_dataset_filename, 'w')\n",
    "\n",
    "    try:\n",
    "        # Définition du type pour les tableaux de floats\n",
    "        varlen_floatarray = h5py.special_dtype(vlen=np.dtype(\"float32\"))\n",
    "\n",
    "        # Calcul de la taille des deux datasets de sortie\n",
    "        train_size = len(train_set)\n",
    "        test_size = len(test_set)\n",
    "        \n",
    "        col_names = [\"pubchem_id\", \"anums\", \"amasses\", \"riken_coords\"]\n",
    "        datatypes = [np.int32, varlen_floatarray, varlen_floatarray, varlen_floatarray]\n",
    "\n",
    "        train_datasets = []\n",
    "        test_datasets = []\n",
    "        \n",
    "        # On créé les quatre datasets (un par colonne) par fichier de sortie\n",
    "        print(\"Creating datasets...\")\n",
    "        for i in range(4):\n",
    "            \n",
    "            train_datasets.append(train_set_h5.create_dataset(col_names[i], shape=(train_size,),\n",
    "                                       dtype=datatypes[i], compression=\"gzip\", \n",
    "                                       chunks=True, maxshape=(None,)))\n",
    "\n",
    "            test_datasets.append(test_set_h5.create_dataset(col_names[i], shape=(test_size,),\n",
    "                                       dtype=datatypes[i], compression=\"gzip\", \n",
    "                                       chunks=True, maxshape=(None,)))\n",
    "\n",
    "            \n",
    "            \n",
    "        # On écrit le dataset d'entraînement en mémoire\n",
    "        print(\"Writing train set in memory...\")\n",
    "        for i in range(train_size):\n",
    "            j=0\n",
    "            for col_name in col_names:\n",
    "                train_datasets[j][i] = train_set[i][j]\n",
    "                j += 1\n",
    "        \n",
    "        # On écrit le dataset de test en mémoire\n",
    "        print(\"Writing test set in memory...\")\n",
    "        for i in range(test_size):\n",
    "            j=0\n",
    "            for col_name in col_names:\n",
    "                test_datasets[j][i] = test_set[i][j]\n",
    "                j += 1\n",
    "\n",
    "\n",
    "        \n",
    "        # On écrit les datasets sur le disque\n",
    "        print(\"Writing train set to disk...\")\n",
    "        train_set_h5.flush()\n",
    "\n",
    "        print(\"Writing test set to disk...\")\n",
    "        test_set_h5.flush()\n",
    "        \n",
    "        print(\"Succesful creation of a train set and a test set\")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "        \n",
    "    finally:\n",
    "        # Closing the files\n",
    "        original_dataset.close()\n",
    "        train_set_h5.close()\n",
    "        test_set_h5.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appel à la fonction de séparation du jeu original en un jeu d'entraînement et un jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SÉPARATION DU JEU ORIGINAL EN UN JEU D'ENTRAÎNEMENT ET UN JEU DE TEST\n",
      "Loading the data...\n",
      "Separation of the data...\n",
      "Creating h5 files...\n",
      "Creating datasets...\n",
      "Writing train set in memory...\n",
      "Writing test set in memory...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ccac6e48e1d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SÉPARATION DU JEU ORIGINAL EN UN JEU D'ENTRAÎNEMENT ET UN JEU DE TEST\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msplit_jeux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_dataset_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-980a40570f78>\u001b[0m in \u001b[0;36msplit_jeux\u001b[0;34m(original_dataset_filename, train_dataset_filename, test_dataset_filename, test_size)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mtest_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Appel à la fonction de séparation du jeu\n",
    "\n",
    "print(\"SÉPARATION DU JEU ORIGINAL EN UN JEU D'ENTRAÎNEMENT ET UN JEU DE TEST\")\n",
    "split_jeux(original_dataset_filename, train_dataset_filename, test_dataset_filename, test_size=test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sortie\n",
    "\n",
    "```\n",
    "SÉPARATION DU JEU ORIGINAL EN UN JEU D'ENTRAÎNEMENT ET UN JEU DE TEST\n",
    "Loading the data...\n",
    "Separation of the data...\n",
    "Creating h5 files...\n",
    "Creating datasets...\n",
    "Writing train set in memory...\n",
    "Writing test set in memory...\n",
    "Writing train set to disk...\n",
    "Writing test set to disk...\n",
    "Succesful creation of a train set and a test set\n",
    "--- 2770.420879125595 seconds ---\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation jeu d'entraînement/jeu d'entraînement minimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction de séparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def creer_h5_ss_ensemble(original_dataset_filename, dataset_dest_filename, taille):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Ouverture du dataset d'entrée en lecture seule\n",
    "    original_dataset =  h5py.File(original_dataset_filename, 'r')\n",
    "    \n",
    "    # Création du dataset minimal de sortie\n",
    "    dataset_reduit_h5 = h5py.File(dataset_dest_filename, 'w')\n",
    "    \n",
    "    try:\n",
    "        # Définition du type spécial\n",
    "        varlen_floatarray = h5py.special_dtype(vlen=np.dtype(\"float32\"))\n",
    "\n",
    "        print(\"Copie des données...\")\n",
    "        \n",
    "        # Copie des premières valeurs de la colonne pubchem_id\n",
    "        dataset_reduit_h5.create_dataset(\"pubchem_id\", shape=(taille,),\n",
    "                                       dtype=np.int32, compression=\"gzip\", \n",
    "                                       chunks=True, maxshape=(None,), \n",
    "                                       data=original_dataset[\"pubchem_id\"][:taille])\n",
    "\n",
    "        # Copie des premières valeurs des autres colonnes\n",
    "        cols = [\"anums\", \"amasses\", \"riken_coords\"]  \n",
    "        for col_name in cols:\n",
    "            dataset_reduit_h5.create_dataset(col_name, shape=(taille,),\n",
    "                                           dtype=varlen_floatarray, compression=\"gzip\", \n",
    "                                           chunks=True, maxshape=(None,), \n",
    "                                           data=original_dataset[col_name][:taille])\n",
    "\n",
    "        dataset_reduit_h5.flush()\n",
    "        print(\"Jeu minimal enregistré avec succès\")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "    finally:\n",
    "        dataset_reduit_h5.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appel de la fonction de création d'un jeu d'entraînement minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"CRÉATION JEU D'ENTRAÎNEMENT MINIMAL\")\n",
    "\n",
    "creer_h5_ss_ensemble(train_dataset_filename, minimal_dataset_filename, minimal_dataset_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sortie\n",
    "\n",
    "```\n",
    "CRÉATION JEU D'ENTRAÎNEMENT MINIMAL\n",
    "Copie des données...\n",
    "Jeu minimal enregistré avec succès\n",
    "--- 1.3850696086883545 seconds ---\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
