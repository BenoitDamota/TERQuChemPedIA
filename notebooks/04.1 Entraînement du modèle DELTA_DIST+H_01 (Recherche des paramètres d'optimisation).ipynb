{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELTA_DIST+H - Recherche des hyperparamètres d'optimisation\n",
    "\n",
    "Le notebook précédent recherchant les hyper-paramètres a conduit à des modèles convergeant très rapidement vers une loss de 18, et n'arrivant pas à aller en deça. C'est problématique car cela revient à estimer les distances  de bruit ajouté à 0.018 près en moyenne, alors qu'on souhaiterait obtenir une précision à 0.001 pour pouvoir optimiser des molécules de façon suffisamment efficace.\n",
    "\n",
    "Nous allons ici redéfinir des fonctions similaires au notebook précédent, mais en faisant varier les hyperparamètres propres à l'optimisation (choix de l'optimiseur, paramètres de l'optimiseur). De plus, nous allons entraîner les modèles sur seulement un million d'exemples, car cela suffira pour voir si l'optimisation converge vite ou non, et jusqu'à quelle loss si oui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_prepared_input_loc = \"../data/minimal_set_riken_v2_prepared_input.h5\"\n",
    "minimal_labels_loc = \"../data/minimal_set_riken_v2_labels.h5\"\n",
    "\n",
    "train_prepared_input_loc = \"../data/train_set_riken_v2_prepared_input.h5\"\n",
    "train_labels_loc = \"../data/train_set_riken_v2_labels.h5\"\n",
    "\n",
    "models_loc = \"../models/DELTA_DIST+H_01/4.1.QUADRI_OPTI/models/\"\n",
    "logs_loc = \"../models/DELTA_DIST+H_01/4.1.QUADRI_OPTI/logs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du RN\n",
    "\n",
    "### Fonctions de coût et d'évaluation du modèle\n",
    "\n",
    "#### Fonction renvoyant le masque des atomes à prendre en compte pour les calculs\n",
    "\n",
    "L'entrée et la sortie du RN étant définies par une méthode de padding, seul un certain nombre d'entrées et de sortie est utilisé pour chaque exemple d'entraînement en fonction du nombre d'atomes de la molécule. On définit ici une fonction qui renvoie le masque des différences de distances à prendre en compte sur les données en entrée et les étiquettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def calcul_masque_atomes_definis(targets):\n",
    "    \"\"\" On calcule le masque booléen des atomes donnés en entrée du RN en fonction du vecteur targets\"\"\"\n",
    "    \n",
    "    # On cherche à obtenir un masque booléen des atomes définis en entrée. Pour cela, on prend en entrée\n",
    "    # les étiquettes sous la forme d'une matrice (200, 4) dont chaque ligne i est la distance de l'atome i avec\n",
    "    # les atomes fictifs du repère. L'atome est indéfini ssi. la somme de la ligne est nulle. En effet,\n",
    "    # un atome défini ne peut pas avoir une distance nulle avec les quatre atomes fictifs, et on veille\n",
    "    # à ce que le vecteurs targets ne contienne que des valeurs nulles pour les atomes non définis.\n",
    "    # On obtient donc un masque booléen de tous les atomes définis en entrée\n",
    "    \n",
    "    ## On somme les distances de chaque atome ##\n",
    "    targets_dists_sums = tf.reduce_sum(targets, 1)\n",
    "    \n",
    "    ## On créé le masque des sommes différentes de zéro ##\n",
    "    \n",
    "    # Création des matrice de True et de False de la dimension de la matrice des sommes (nécessaires\n",
    "    # pour tf.where)\n",
    "    zeros = tf.cast(tf.zeros_like(targets_dists_sums),dtype=tf.bool)\n",
    "    ones = tf.cast(tf.ones_like(targets_dists_sums),dtype=tf.bool)\n",
    "    \n",
    "    return tf.where(targets_dists_sums>0, ones, zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de coût"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_rmse(predictions, targets):\n",
    "    \"\"\" Calcule le RMSE partiel des prédictions par rapport aux valeurs attendues. Le RMSE est partiel car\n",
    "    on ne le calcule que pour les sorties correspondant aux atomes donnés en entrée. En d'autres\n",
    "    termes, on ne pousse pas le modèle à donner des distances nulles pour les atomes indéfinis\n",
    "    en entrée\"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"partial_rmse\"):\n",
    "\n",
    "        # On met les prédictions et les cibles sous la forme d'une matrice (200, 4)\n",
    "        predictions = tf.reshape(predictions, [-1, 4])\n",
    "        targets = tf.reshape(targets, [-1, 4])\n",
    "\n",
    "        # On calcule le masque des atomes définis selon les cibles\n",
    "        defined_atoms_mask = calcul_masque_atomes_definis(targets)\n",
    "        \n",
    "        # On masque les prédictions et les étiquettes selon le masque des atomes définis\n",
    "        targets_masked = tf.boolean_mask(targets, defined_atoms_mask)\n",
    "        predictions_masked = tf.boolean_mask(predictions, defined_atoms_mask)   \n",
    "\n",
    "        return tf.sqrt(tf.reduce_mean(tf.squared_difference(predictions_masked, targets_masked)), name=\"rmse\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'évaluation des performances (score R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_r2_score(predictions, targets, inputs):\n",
    "    \"\"\" Renvoie le score R2 de la prédiction (le calcul est effectué uniquement sur les résultats\n",
    "    des atomes donnés en entrée) \"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"partial_r2\"):\n",
    "    \n",
    "        # On met les prédictions et les cibles sous la forme d'une matrice (200, 4)\n",
    "        predictions = tf.reshape(predictions, [-1, 4])\n",
    "        targets = tf.reshape(targets, [-1, 4])\n",
    "\n",
    "        # On calcule le masque des atomes définis selon les cibles\n",
    "        defined_atoms_mask = calcul_masque_atomes_definis(targets)\n",
    "\n",
    "        # On masque les prédictions et les étiquettes selon le masque des atomes définis\n",
    "        targets_masked = tf.boolean_mask(targets, defined_atoms_mask)\n",
    "        predictions_masked = tf.boolean_mask(predictions, defined_atoms_mask)\n",
    "\n",
    "        # Calcul de l'erreur totale\n",
    "        total_error = tf.reduce_sum(tf.square(tf.subtract(targets, tf.reduce_mean(targets_masked))))\n",
    "\n",
    "        # Calcul de l'erreur inexpliquée\n",
    "        unexplained_error = tf.reduce_sum(tf.square(tf.subtract(targets_masked, predictions_masked)))\n",
    "\n",
    "        r2 = tf.subtract(1.0, tf.divide(unexplained_error, total_error), \"r2_score\")\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du RN\n",
    "\n",
    "### Fonctions de coût et d'évaluation du modèle\n",
    "\n",
    "Les fonctions ci-dessous sont très fortement inspirées du travail de Nicolas Roux lors de son TER de M1 en 2017. Les différences sont les suivantes.\n",
    "\n",
    "* Calcul du RMSE uniquement sur les atomes définis\n",
    "* Utilisation d'un score R2 pour la validation\n",
    "* Recherche par quadrillage des hyper-paramètres\n",
    "\n",
    "#### Fonction renvoyant le masque des atomes à prendre en compte pour les calculs\n",
    "\n",
    "L'entrée et la sortie du RN étant définies par une méthode de padding, seul un certain nombre d'entrées et de sortie est utilisé pour chaque exemple d'entraînement en fonction du nombre d'atomes de la molécule. On définit ici une fonction qui renvoie le masque des différences de distances à prendre en compte sur les données en entrée et les étiquettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def calcul_masque_atomes_definis(targets):\n",
    "    \"\"\" On calcule le masque booléen des atomes donnés en entrée du RN en fonction du vecteur targets\"\"\"\n",
    "    \n",
    "    # On cherche à obtenir un masque booléen des atomes définis en entrée. Pour cela, on prend en entrée\n",
    "    # les étiquettes sous la forme d'une matrice (200, 4) dont chaque ligne i est la distance de l'atome i avec\n",
    "    # les atomes fictifs du repère. L'atome est indéfini ssi. la somme de la ligne est nulle. En effet,\n",
    "    # un atome défini ne peut pas avoir une distance nulle avec les quatre atomes fictifs, et on veille\n",
    "    # à ce que le vecteurs targets ne contienne que des valeurs nulles pour les atomes non définis.\n",
    "    # On obtient donc un masque booléen de tous les atomes définis en entrée\n",
    "    \n",
    "    ## On somme les distances de chaque atome ##\n",
    "    targets_dists_sums = tf.reduce_sum(targets, 1)\n",
    "    \n",
    "    ## On créé le masque des sommes différentes de zéro ##\n",
    "    \n",
    "    # Création des matrice de True et de False de la dimension de la matrice des sommes (nécessaires\n",
    "    # pour tf.where)\n",
    "    zeros = tf.cast(tf.zeros_like(targets_dists_sums),dtype=tf.bool)\n",
    "    ones = tf.cast(tf.ones_like(targets_dists_sums),dtype=tf.bool)\n",
    "    \n",
    "    return tf.where(targets_dists_sums>0, ones, zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de coût"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_rmse(predictions, targets):\n",
    "    \"\"\" Calcule le RMSE partiel des prédictions par rapport aux valeurs attendues. Le RMSE est partiel car\n",
    "    on ne le calcule que pour les sorties correspondant aux atomes donnés en entrée. En d'autres\n",
    "    termes, on ne pousse pas le modèle à donner des distances nulles pour les atomes indéfinis\n",
    "    en entrée\"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"partial_rmse\"):\n",
    "\n",
    "        # On met les prédictions et les cibles sous la forme d'une matrice (200, 4)\n",
    "        predictions = tf.reshape(predictions, [-1, 4])\n",
    "        targets = tf.reshape(targets, [-1, 4])\n",
    "\n",
    "        # On calcule le masque des atomes définis selon les cibles\n",
    "        defined_atoms_mask = calcul_masque_atomes_definis(targets)\n",
    "        \n",
    "        # On masque les prédictions et les étiquettes selon le masque des atomes définis\n",
    "        targets_masked = tf.boolean_mask(targets, defined_atoms_mask)\n",
    "        predictions_masked = tf.boolean_mask(predictions, defined_atoms_mask)   \n",
    "\n",
    "        return tf.sqrt(tf.reduce_mean(tf.squared_difference(predictions_masked, targets_masked)), name=\"rmse\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'évaluation des performances (score R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_r2_score(predictions, targets, inputs):\n",
    "    \"\"\" Renvoie le score R2 de la prédiction (le calcul est effectué uniquement sur les résultats\n",
    "    des atomes donnés en entrée) \"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"partial_r2\"):\n",
    "    \n",
    "        # On met les prédictions et les cibles sous la forme d'une matrice (200, 4)\n",
    "        predictions = tf.reshape(predictions, [-1, 4])\n",
    "        targets = tf.reshape(targets, [-1, 4])\n",
    "\n",
    "        # On calcule le masque des atomes définis selon les cibles\n",
    "        defined_atoms_mask = calcul_masque_atomes_definis(targets)\n",
    "\n",
    "        # On masque les prédictions et les étiquettes selon le masque des atomes définis\n",
    "        targets_masked = tf.boolean_mask(targets, defined_atoms_mask)\n",
    "        predictions_masked = tf.boolean_mask(predictions, defined_atoms_mask)\n",
    "\n",
    "        # Calcul de l'erreur totale\n",
    "        total_error = tf.reduce_sum(tf.square(tf.subtract(targets, tf.reduce_mean(targets_masked))))\n",
    "\n",
    "        # Calcul de l'erreur inexpliquée\n",
    "        unexplained_error = tf.reduce_sum(tf.square(tf.subtract(targets_masked, predictions_masked)))\n",
    "\n",
    "        r2 = tf.subtract(1.0, tf.divide(unexplained_error, total_error), \"r2_score\")\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition d'une fonction créant le RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.optimizers import Adam\n",
    "\n",
    "\n",
    "def creer_1k_4x8650_800(epsilon, learning_rate):\n",
    "    \"\"\" Fonction créant un réseau de neurones de type fully connected, ayant une couche d'entrée de 1000\n",
    "    neurones, quatre couches cachées de 8650 neurones et une sortie de 800 neurones\n",
    "    Inputs : hyperparamètres de l'optimizer adam\n",
    "    \"\"\"\n",
    "    do = 0.99\n",
    "    stddev_init = 0.001\n",
    "\n",
    "    # On créé l'initialisateur de tenseur avec une loi normale tronquée. sigma = stddev_init, et les \n",
    "    # valeurs à plus de 2sigma sont re-tirées\n",
    "    winit = tfl.initializations.truncated_normal(stddev=stddev_init, dtype=tf.float32, seed=None)\n",
    "    \n",
    "    # On créé l'input du RN\n",
    "    network = input_data(shape=[None, 1000], name='input')\n",
    "\n",
    "    \n",
    "    # On créé les trois couches cachées\n",
    "    for i in range(4):\n",
    "        network = fully_connected(network, 8650, activation='relu', name='fc'+str(i), weights_init=winit)\n",
    "        # On détruit des neurones aléatoirement avec une la probabilité donnée en entrée\n",
    "        network = dropout(network, do)\n",
    "    \n",
    "    # On ajoute la couche de sortie du réseau\n",
    "    # Fonction d'activation prelu\n",
    "    # Initilisée avec la loi normale tronquée\n",
    "    network = fully_connected(network, 800, activation='prelu', name='outlayer', weights_init=winit)\n",
    "    \n",
    "    adam = Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
    "    \n",
    "    # Couche d'évaluation du modèle. Utilisation d'une descente stochastique Adam\n",
    "    # Learning rate = 0.05\n",
    "    # Loss = fonction définie rmse\n",
    "    network = regression(network, optimizer=adam,\n",
    "    loss=partial_rmse, metric=partial_r2_score, name='target')\n",
    "            \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Préparation des données\n",
    "\n",
    "#### Fonction renvoyant deux sous-ensembles du jeu d'entrainement : un ensemble d'exemples et les cibles correspondantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(train_set, targets, reduce_train_fold_size):\n",
    "    \"\"\" Permet d'obtenir un sous-ensemble du jeu d'entraînement afin de ne pas travailler sur le jeu\n",
    "    d'entraînement total pour la recherche par quadrillage et donc de gagner du temps d'exécution. L'idée\n",
    "    et que si un ensemble d'hyper-paramètres produit des meilleurs résultats que les autres ensembles\n",
    "    d'hyper-paramètres sur l'ensemble du jeu d'entraînement, alors on suppose que ce sera également \n",
    "    le cas sur une partie des données. \"\"\"\n",
    "\n",
    "    return (train_set[\"inputs\"][:reduce_train_fold_size], targets[\"targets\"][:reduce_train_fold_size])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement des modèles\n",
    "\n",
    "#### Fonction d'entraînement de modèles pour recherche des meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tflearn as tfl\n",
    "import time\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def train(input_path, targets_path, fold_size, samples_per_batch, epochs):\n",
    "    \n",
    "    \n",
    "    learning_rate_vals = [0.001, 0.0001]\n",
    "    epsilon_vals = [0.1, 1e-8]\n",
    "\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    inputs_h5 = h5py.File(input_path, 'r')\n",
    "    targets_h5 = h5py.File(targets_path, 'r')\n",
    "    \n",
    "    input_X, labels_y = get_fold(inputs_h5, targets_h5, fold_size)\n",
    "\n",
    "    \n",
    "    # On itère sur toutes les combinaisons d'hyperparamètres\n",
    "    for learning_rate in learning_rate_vals:\n",
    "        for epsilon in epsilon_vals:\n",
    "                                \n",
    "            tf.reset_default_graph()\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            nom_modele = \"DELTA_DIST+H_01_hyperparam_lr-\"+str(learning_rate)+\"_epsilon_\"+str(epsilon)\n",
    "\n",
    "            print()\n",
    "            print(\"Training model \"+nom_modele)\n",
    "        \n",
    "            # On créé le réseau avec les hyperparamètres courants\n",
    "            network = creer_1k_4x8650_800(learning_rate, epsilon)\n",
    "\n",
    "            # On créé le modèle\n",
    "            model = tfl.DNN(network, tensorboard_verbose=3, tensorboard_dir=logs_loc)\n",
    "\n",
    "            print(\"Début entraînement\")\n",
    "\n",
    "            # Entraînement\n",
    "            model.fit(X_inputs=input_X,Y_targets=labels_y, batch_size=samples_per_batch,\n",
    "                      shuffle = True, snapshot_step=100, validation_set=0.1,\n",
    "                      show_metric=True, run_id=\"hyperparametres_\"+nom_modele , n_epoch=epochs)\n",
    "\n",
    "            model.save(models_loc+\"test_\" + nom_modele)\n",
    "\n",
    "            print(\"Temps d'entraînement du modèle : \")\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "            inputs_h5.close()\n",
    "            targets_h5.close()\n",
    "    \n",
    "    \n",
    "    print(\"Temps total :\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - total_start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model DELTA_DIST+H_01_hyperparam_lr-0.001_epsilon_0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [800] and type float\n\t [[Node: outlayer/b/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [800] values: 0 0 0...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'outlayer/b/Adam/Initializer/zeros', defined at:\n  File \"/home/etudiant/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/etudiant/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-6e40b1763503>\", line 4, in <module>\n    train(minimal_prepared_input_loc, minimal_labels_loc, 100000, 1000, 2)\n  File \"<ipython-input-31-ab777c33ba94>\", line 41, in train\n    model = tfl.DNN(network, tensorboard_verbose=3, tensorboard_dir=logs_loc)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tflearn/models/dnn.py\", line 65, in __init__\n    best_val_accuracy=best_val_accuracy)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tflearn/helpers/trainer.py\", line 131, in __init__\n    clip_gradients)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tflearn/helpers/trainer.py\", line 705, in initialize_training_ops\n    name=\"apply_grad_op_\" + str(i))\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 552, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 984, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 179, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 153, in create_slot_with_initializer\n    dtype)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 337, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 784, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 99, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1601, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2583, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [800] and type float\n\t [[Node: outlayer/b/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [800] values: 0 0 0...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [800] and type float\n\t [[Node: outlayer/b/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [800] values: 0 0 0...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6e40b1763503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# et deux époques d'entraînement par modèle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#train(train_prepared_input_loc, train_labels_loc, 2000000, 1000, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminimal_prepared_input_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimal_labels_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-ab777c33ba94>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_path, targets_path, fold_size, samples_per_batch, epochs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# On créé le modèle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_verbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Début entraînement\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, network, clip_gradients, tensorboard_verbose, tensorboard_dir, checkpoint_path, best_checkpoint_path, max_checkpoints, session, best_val_accuracy)\u001b[0m\n\u001b[1;32m     63\u001b[0m                                \u001b[0mmax_checkpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_checkpoints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                                \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                                best_val_accuracy=best_val_accuracy)\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train_ops, graph, clip_gradients, tensorboard_dir, tensorboard_verbose, checkpoint_path, best_checkpoint_path, max_checkpoints, keep_checkpoint_every_n_hours, random_seed, session, best_val_accuracy)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;31m# Fix for re-using sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m#initialize_uninit_variables(self.session)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [800] and type float\n\t [[Node: outlayer/b/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [800] values: 0 0 0...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'outlayer/b/Adam/Initializer/zeros', defined at:\n  File \"/home/etudiant/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/etudiant/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-6e40b1763503>\", line 4, in <module>\n    train(minimal_prepared_input_loc, minimal_labels_loc, 100000, 1000, 2)\n  File \"<ipython-input-31-ab777c33ba94>\", line 41, in train\n    model = tfl.DNN(network, tensorboard_verbose=3, tensorboard_dir=logs_loc)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tflearn/models/dnn.py\", line 65, in __init__\n    best_val_accuracy=best_val_accuracy)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tflearn/helpers/trainer.py\", line 131, in __init__\n    clip_gradients)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tflearn/helpers/trainer.py\", line 705, in initialize_training_ops\n    name=\"apply_grad_op_\" + str(i))\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 552, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 984, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 179, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 153, in create_slot_with_initializer\n    dtype)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 337, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 784, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 99, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1601, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2583, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [800] and type float\n\t [[Node: outlayer/b/Adam/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [800] values: 0 0 0...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# On fait la recherche par quadrillage sur deux millions et demi d'exemples avec une taille de batch de 1000 \n",
    "# et une seule époque d'entraînement par modèle\n",
    "train(train_prepared_input_loc, train_labels_loc, 2500000, 1000, 1)\n",
    "#train(minimal_prepared_input_loc, minimal_labels_loc, 100000, 1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
