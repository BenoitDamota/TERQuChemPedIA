{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation du jeu de données PubChem - Distances absolues et relatives\n",
    "\n",
    "Quels que soient les hyperparamètres des modèles que l'on entraîne (voir notebooks précédents), les réseaux apprennent très vite et sont bloqués dans leur apprentissage à environ 62% de la RMSE introduite par le bruit. Par exemple, lorsqu'on introduit un bruit de RMSE 170, le RMSE des prédictions des réseaux ne descend pas en dessous de 107, alors qu'on souhaiterait qu'il soit dans un ordre de grandeur situé entre 0 et 10.\n",
    "\n",
    "La raison de ce manque de performances est peut-être le manque d'informations en entrée du réseau. Nous allons donc créér un jeu de données d'entrée contenant, en plus des distances aux points fixés du repère (les atomes fictifs), les distances inter-atomiques de la diagonale de largeur 4 de la matrice de distances, comme il était prévu dans la version initiale du réseau, avant que l'on ne réalise qu'il était impossible de reconstruire les positions des grosses molécules à partir de cette diagonale (voir notebook 2.0).\n",
    "\n",
    "Ici, on va garder les distances aux points fixes du repère en sortie du réseau, on pourra donc reconstruire les positions des atomes des molécules si ce modèle s'avère efficace. Toutefois, nous allons en profiter pour créér un deuxième jeu d'étiquettes pour lequel le modèle devra prédire les distances inter-atomiques de la diagonale de la matrice de distances de largeur 4. Si le modèle prédisant les distances relatives s'avère plus efficace, alors il ne sera certes pas viable car on ne pourra pas reconstruire les molécules à partir de ses prédictions, mais cela indiquera que les mauvais résultats que nous avons jusque là sont dûs au format des données que nous attendons en sortie. \n",
    "\n",
    "Le bruit que nous allons introduire dans les jeux de données que nous allons préparer ici sera un bruit important (de RMSE 170), car il permettra d'évaluer facilement la qualité des modèles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chemin des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_location = \"../data/test_set_riken_v2.h5\"\n",
    "test_set_prepared_input_abs_rel_location = \"../data/test_set_riken_v2_prepared_input_bruit+_abs_rel.h2\"\n",
    "test_set_labels_abs_location = \"../data/test_set_riken_v2_labels_bruit+_abs.h2\"\n",
    "test_set_labels_rel_location = \"../data/test_set_riken_v2_labels_bruit+_rel.h2\"\n",
    "\n",
    "train_set_location = \"../data/train_set_riken_v2.h5\"\n",
    "train_set_prepared_input_abs_rel_location = \"../data/train_set_riken_v2_prepared_input_bruit+_abs_rel.h5\"\n",
    "train_set_labels_abs_location = \"../data/train_set_riken_v2_labels_bruit+_abs.h5\"\n",
    "train_set_labels_rel_location = \"../data/train_set_riken_v2_labels_bruit+_rel.h5\"\n",
    "\n",
    "minimal_set_riken_location = \"../data/minimal_set_riken_v2.h5\"\n",
    "minimal_set_prepared_input_abs_rel_location = \"../data/minimal_set_riken_v2_prepared_input_bruit+_abs_rel.h5\"\n",
    "minimal_set_labels_abs_location = \"../data/minimal_set_riken_v2_labels_bruit+_abs.h5\"\n",
    "minimal_set_labels_rel_location = \"../data/minimal_set_riken_v2_labels_bruit+_rel.h5\"\n",
    "\n",
    "mini_set_riken_location = \"../data/mini_set.h5\"\n",
    "mini_set_prepared_input_abs_rel_location = \"../data/mini_set_prepared_input_bruit+_abs_rel.h5\"\n",
    "mini_set_labels_abs_location = \"../data/mini_set_labels_bruit+_abs.h5\"\n",
    "mini_set_labels_rel_location = \"../data/mini_set_labels_bruit+_rel.h5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction d'ajout de bruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def positions_bruitees(positions):    \n",
    "    bruit = np.random.normal(loc=0.0, scale=0.1732, size=positions.shape)\n",
    "    return ((positions + bruit), bruit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction de calcul de la matrice de distances aux points du repère fixes compressée à partir de la matrice des coordonnées des atomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_distances_compr_abs(positions):\n",
    "    \"\"\" Renvoie la matrice de distances compressée des positions des atomes passées en paramètres\n",
    "    La matrice de distances compressée est définie de la façon suivante : pour chaque atome, on calcule\n",
    "    la distance avec chaque point du repère. Une ligne i de la matrice (n,4) correspond aux distances\n",
    "    de l'atome i avec chacun des quatre points du repère\"\"\"\n",
    "    \n",
    "    nb_at = len(positions)\n",
    "    \n",
    "    # On renvoie un tableau vide si la molécule est vide\n",
    "    if nb_at == 0:\n",
    "        return []\n",
    "    \n",
    "    repere = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    repere = np.vstack([repere]*nb_at)\n",
    "\n",
    "    positions = np.tile(positions, 4).reshape(4*nb_at, 3)\n",
    "    \n",
    "    return np.sqrt(np.sum(np.power(positions-repere, 2), 1)).reshape(nb_at, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction de calcul de matrice de distances relatives (diagonale de largeur quatre)  partir des coordonnées des atomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def get_atome_coord(positions, index):\n",
    "    \"\"\" Renvoie les coordonnées de l'atome ayant l'index donné \"\"\"\n",
    "    return (positions[index])\n",
    "    \n",
    "def calcul_distance(pt1, pt2):\n",
    "    \"\"\" Renvoie la distance entre deux points représentés par leurs coordonnées (x, y, z) dans deux tableaux\n",
    "    de forme (1, 3)\"\"\"\n",
    "    return np.sqrt(np.sum(np.square(np.diff(np.array([pt1, pt2]), axis=0))))\n",
    "\n",
    "def get_val_dist_matrice(i, j, positions):\n",
    "    \"\"\" Renvoie la valeur de la matrice de distances aux coordonnées (i, j). La matrice complète n'est\n",
    "    jamais calculée. \"\"\"\n",
    "    coord_i = get_atome_coord(positions, i)  # Coordonnées de l'atome i\n",
    "    coord_j = get_atome_coord(positions, j)  # Coordonnées de l'atome j\n",
    "\n",
    "    return calcul_distance(coord_i, coord_j)\n",
    "    \n",
    "def matrice_distances_compr_rel(positions):\n",
    "    \"\"\" Renvoie la matrice de distances à partir des coordonnées des atomes et du nombre d'atomes dans\n",
    "    la molécule. La matrice de distances complète n'est pas générée, seules les valeurs nécessaires\n",
    "    sont calculées à la demande \"\"\"\n",
    "    \n",
    "    nb_atomes = positions.shape[0]\n",
    "    \n",
    "    mat_distances = np.zeros(shape=(nb_atomes,4))\n",
    "    \n",
    "    for j in range(nb_atomes):\n",
    "        k=0  # Permet d'accéder simplement à l'indice dans le tableau de sortie\n",
    "        for i in range(j+1, j+5):\n",
    "            if i < nb_atomes:\n",
    "                mat_distances[j][k] = get_val_dist_matrice(i, j, positions)\n",
    "            k += 1\n",
    "            \n",
    "    return mat_distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de création des entrées et des labels des RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def creation_input_RN(set_location, input_rn_location_rel_abs, labels_location_abs,\n",
    "                      labels_location_rel, epochs, nb_mol_mem):\n",
    "    \n",
    "    \"\"\" nb_mol_mem est le nombre maximal de molécules que l'on stocke simultanément en mémoire. Lorsque la \n",
    "    taille est atteinte, on écrit les entrées du RN et les cibles du RN sur le disque (taille max des\n",
    "    batchs de traitement) \n",
    "    La nécessité d'utiliser des batchs de traitement en mémoire est due au fait que le traitement devient très\n",
    "    long si on ne met pas de données en mémoire et qu'on écrit sur le disque à chaque itération. En utilisant\n",
    "    les batchs, l'écriture sur le disque se fait en bloc.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()    \n",
    "    mol_vides = 0\n",
    "    \n",
    "    rmse_epochs_rel = []\n",
    "    rmse_epochs_abs = []\n",
    "    \n",
    "    print(\"Creating input and label sets for \"+set_location+\" : \")\n",
    "\n",
    "    # On charge le jeu de données original (en lecture seule)\n",
    "    original_dataset_h5 = h5py.File(set_location, 'r')\n",
    "    \n",
    "    # On enregistre la taille du jeu de données\n",
    "    taille = len(original_dataset_h5[\"anums\"])\n",
    "    \n",
    "    # On créé les jeux de données d'entrée du RN et de labels\n",
    "    input_rn_dataset_h5 = h5py.File(input_rn_location_rel_abs, 'w')\n",
    "    labels_dataset_abs_h5 = h5py.File(labels_location_abs, 'w')\n",
    "    labels_dataset_rel_h5 = h5py.File(labels_location_rel, 'w')\n",
    "\n",
    "    \n",
    "    # On créé les datasets inputs et targets \n",
    "    input_dataset = input_rn_dataset_h5.create_dataset(\"inputs\", shape=(epochs*taille, 1800),\n",
    "                                       dtype=np.float32, compression=\"gzip\", \n",
    "                                       chunks=True)\n",
    "\n",
    "    targets_dataset_abs = labels_dataset_abs_h5.create_dataset(\"targets\", shape=(epochs*taille, 800),\n",
    "                                       dtype=np.float32, compression=\"gzip\", \n",
    "                                       chunks=True)\n",
    "    \n",
    "    targets_dataset_rel = labels_dataset_rel_h5.create_dataset(\"targets\", shape=(epochs*taille, 800),\n",
    "                                       dtype=np.float32, compression=\"gzip\", \n",
    "                                       chunks=True)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            \n",
    "            print(\"Epoch \"+str(k)+\"...\")\n",
    "\n",
    "            # Contient les rmse de tous les bruits ajoutés à chaque molécule durant toute l'époque de génération\n",
    "            # de l'entrée du RN. À la fin de l'époque, on en fait la moyenne et on l'ajoute à rmse_epochs\n",
    "            bruits_epoch_rmse_abs = np.empty(shape=(taille,), dtype=np.float32)\n",
    "            bruits_epoch_rmse_rel = np.empty(shape=(taille,), dtype=np.float32)\n",
    "           \n",
    "            input_coords = np.array(original_dataset_h5[\"riken_coords\"])\n",
    "            input_masses = np.array(original_dataset_h5[\"amasses\"])\n",
    "            \n",
    "            # Indice de la première molécule traitée du batch courant\n",
    "            indice_batch_courant = -nb_mol_mem\n",
    "            \n",
    "            # On parcourt toutes les molécules\n",
    "            for i in range(taille):\n",
    "\n",
    "                # On arrive au début d'un nouveau batch de traitement\n",
    "                if i%nb_mol_mem == 0:\n",
    "                    \n",
    "                    # On écrit les données du batch précédent sur le disque s'il existe un batch précédent\n",
    "                    if indice_batch_courant >= 0 :\n",
    "                        print(\"Writing data to h5 for epoch \"+str(k)+\" and indexes from \"+\n",
    "                              str(indice_batch_courant)+\" to \"+str(indice_batch_courant+taille_batch_courant))\n",
    "                        \n",
    "                        input_dataset[k*taille+indice_batch_courant: \n",
    "                                      k*taille+indice_batch_courant+taille_batch_courant] = np_input_dataset\n",
    "                        \n",
    "                        targets_dataset_abs[k*taille+indice_batch_courant: \n",
    "                                            k*taille+indice_batch_courant+taille_batch_courant] = np_targets_dataset_abs\n",
    "                        \n",
    "                        targets_dataset_rel[k*taille+indice_batch_courant: \n",
    "                                            k*taille+indice_batch_courant+taille_batch_courant] = np_targets_dataset_rel\n",
    "                        \n",
    "                        \n",
    "                    # On met à jour la première molécule du batch courant\n",
    "                    indice_batch_courant += nb_mol_mem\n",
    "                    \n",
    "                    # On calcule la taille du nouveau batch\n",
    "                    taille_batch_courant = min(nb_mol_mem, taille - i)\n",
    "                    \n",
    "                    print(\"Computing new batch...\")\n",
    "                        \n",
    "                    # On créé les nouveaux tableaux en mémoire du batch courant\n",
    "                    np_input_dataset = np.empty(shape=(taille_batch_courant, 1800))\n",
    "                    np_targets_dataset_abs = np.empty(shape=(taille_batch_courant, 800))\n",
    "                    np_targets_dataset_rel = np.empty(shape=(taille_batch_courant, 800))\n",
    "                                   \n",
    "                # On récupère les coordonnées de la molécule courante\n",
    "                coords = np.array(input_coords[i]).reshape(-1,3)\n",
    "\n",
    "                # On ajoute les positions des atomes fictifs aux coordonnées\n",
    "                points_fictifs = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "                coords = np.concatenate([points_fictifs, coords])\n",
    "                \n",
    "                # On calcule les matrices de distances aux points fixes et de distances relatives\n",
    "                dist_init_abs = matrice_distances_compr_abs(coords)\n",
    "                dist_init_rel = matrice_distances_compr_rel(coords)\n",
    "                \n",
    "                # On insère le bruit sur les coordonnées\n",
    "                coords_bruit, bruit = positions_bruitees(coords)\n",
    "                coords_bruit = coords_bruit.reshape(-1, 3)\n",
    "                bruit = bruit.reshape(-1, 3)\n",
    "\n",
    "                if len(coords) == 0:\n",
    "                    mol_vides += 1\n",
    "                else:\n",
    "                    # On calcule les différence de distances cibles (en mÅ) et les distances bruitées (en Å),\n",
    "                    # pour les distances relatives et absolues\n",
    "                    dist_bruit_abs = matrice_distances_compr_abs(coords_bruit)\n",
    "                    dist_bruit_rel = matrice_distances_compr_rel(coords_bruit)\n",
    "                    delta_dist_targets_abs = (dist_init_abs - dist_bruit_abs)*1000\n",
    "                    delta_dist_targets_rel = (dist_init_rel - dist_bruit_rel)*1000\n",
    "\n",
    "\n",
    "                # On récupère les masses atomiques de la molécule courante\n",
    "                masses = input_masses[i]\n",
    "\n",
    "                # On initialise l'entrée du RN et le vecteur cible pour la molécule courante\n",
    "                entree_courante = np.zeros(shape=(1800, 1))\n",
    "                cible_courante_abs = np.zeros(shape=(200, 4))\n",
    "                cible_courante_rel = np.zeros(shape=(200, 4))\n",
    "\n",
    "\n",
    "                # On ajoute les coordonnées bruitées et les masses à l'entrée avec padding, et les coordonnées\n",
    "                # cibles au dataset targets\n",
    "                j=0\n",
    "                for masse in masses:\n",
    "\n",
    "                    # Ajout des distances absolues, des distances relatives et de la masse au vecteur entrée\n",
    "                    index_input_courant = j*9\n",
    "                    entree_courante[index_input_courant:index_input_courant+4] = dist_bruit_abs[j].reshape(4,1)\n",
    "                    entree_courante[index_input_courant+4:index_input_courant+8] = dist_bruit_abs[j].reshape(4,1)\n",
    "                    entree_courante[index_input_courant+8] = masse\n",
    "\n",
    "                    # Ajout des données aux matrices cible\n",
    "                    cible_courante_abs[j] = delta_dist_targets_abs[j]\n",
    "                    cible_courante_rel[j] = delta_dist_targets_rel[j]\n",
    "\n",
    "                    j+=1\n",
    "\n",
    "                # On aplatit les matrices cible\n",
    "                cible_courante_abs = cible_courante_abs.reshape(1, 800)\n",
    "                cible_courante_rel = cible_courante_rel.reshape(1, 800)\n",
    "\n",
    "                # On insère les données dans le tableau np en mémoire\n",
    "                np_input_dataset[i%taille_batch_courant] = entree_courante.reshape(-1, 1800)\n",
    "                np_targets_dataset_abs[i%taille_batch_courant] = cible_courante_abs\n",
    "                np_targets_dataset_rel[i%taille_batch_courant] = cible_courante_rel\n",
    "\n",
    "                # On ajoute le rmse ajouté à la molécule au tableau des rmse de l'époque\n",
    "                np_delta_dist_targets_abs = np.array(delta_dist_targets_abs)\n",
    "                np_delta_dist_targets_rel = np.array(delta_dist_targets_rel)\n",
    "                bruits_epoch_rmse_abs[i] = np.sqrt(np.mean(np.square(np_delta_dist_targets_abs)))\n",
    "                bruits_epoch_rmse_rel[i] = np.sqrt(np.mean(np.square(np_delta_dist_targets_rel)))\n",
    "                \n",
    "            \n",
    "            \n",
    "            print(\"end epoch\")\n",
    "            # On ajoute les données du dernier batch\n",
    "            print(\"Writing data to h5 for epoch \"+str(k)+\" and indexes from \"+\n",
    "                              str(indice_batch_courant)+\" to \"+str(indice_batch_courant+taille_batch_courant))\n",
    "                        \n",
    "            input_dataset[k*taille+indice_batch_courant: \n",
    "                          k*taille+indice_batch_courant+taille_batch_courant] = np_input_dataset\n",
    "\n",
    "            targets_dataset_abs[k*taille+indice_batch_courant: \n",
    "                                k*taille+indice_batch_courant+taille_batch_courant] = np_targets_dataset_abs\n",
    "\n",
    "            targets_dataset_rel[k*taille+indice_batch_courant: \n",
    "                                k*taille+indice_batch_courant+taille_batch_courant] = np_targets_dataset_rel\n",
    "\n",
    "                \n",
    "            # On ajoute le rmse moyen de l'époque au tableau des rmse de toutes les époques\n",
    "            rmse_epochs_abs.append(np.mean(bruits_epoch_rmse_abs))\n",
    "            rmse_epochs_rel.append(np.mean(bruits_epoch_rmse_rel))\n",
    "            \n",
    "            \n",
    "          \n",
    "\n",
    "        print(\"Writing datasets to disk\")\n",
    "        input_rn_dataset_h5.flush()\n",
    "        labels_dataset_abs_h5.flush()\n",
    "        labels_dataset_rel_h5.flush()\n",
    "\n",
    "        \n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        # On calcule le rmse moyen de toutes les époques\n",
    "        np_rmse_epochs_abs = np.array(rmse_epochs_abs)\n",
    "        np_rmse_epochs_rel = np.array(rmse_epochs_rel)\n",
    "        print(\"RMSE bruit moyen dist absolues : \"+str(np.mean(np_rmse_epochs_abs)))\n",
    "        print(\"RMSE bruit moyen dist relatives : \"+str(np.mean(np_rmse_epochs_rel)))\n",
    "\n",
    "        \n",
    "    finally:\n",
    "        original_dataset_h5.close()\n",
    "        input_rn_dataset_h5.close()\n",
    "        labels_dataset_abs_h5.close()\n",
    "        labels_dataset_rel_h5.close()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des données d'entrée du RN et des labels pour le jeu minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_input_RN(minimal_set_riken_location, minimal_set_prepared_input_abs_rel_location,\n",
    "                  minimal_set_labels_abs_location, minimal_set_labels_rel_location, 3, 500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sortie\n",
    "\n",
    "```\n",
    "Creating input and label sets for ../data/minimal_set_riken_v2.h5 :\n",
    "Epoch 0...\n",
    "Computing new batch...\n",
    "end epoch\n",
    "Writing data to h5 for epoch 0 and indexes from 0 to 100000\n",
    "Epoch 1...\n",
    "Computing new batch...\n",
    "\n",
    "end epoch\n",
    "Writing data to h5 for epoch 1 and indexes from 0 to 100000\n",
    "Epoch 2...\n",
    "Computing new batch...\n",
    "end epoch\n",
    "Writing data to h5 for epoch 2 and indexes from 0 to 100000\n",
    "Writing datasets to disk\n",
    "--- 2636.2060313224792 seconds ---\n",
    "RMSE bruit moyen dist absolues : 177.54662\n",
    "RMSE bruit moyen dist relatives : 233.56984\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des données d'entrée du RN et des labels pour le jeu d'entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input and label sets for ../data/train_set_riken_v2.h5 : \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '../data/train_set_riken_v2.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-3a6cdb558a95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m creation_input_RN(train_set_location, train_set_prepared_input_abs_rel_location,\n\u001b[0;32m----> 2\u001b[0;31m                   train_labels_abs_loc, train_labels_rel_loc, 3, 500000)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-126-2f5ae1090617>\u001b[0m in \u001b[0;36mcreation_input_RN\u001b[0;34m(set_location, input_rn_location_rel_abs, labels_location_abs, labels_location_rel, epochs, nb_mol_mem)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# On charge le jeu de données original (en lecture seule)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moriginal_dataset_h5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# On enregistre la taille du jeu de données\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '../data/train_set_riken_v2.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "creation_input_RN(train_set_location, train_set_prepared_input_abs_rel_location,\n",
    "                  train_set_labels_abs_location, train_set_labels_rel_location, 3, 500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sortie\n",
    "\n",
    "```\n",
    "Creating input and label sets for ../data/train_set_riken_v2.h5 :\n",
    "Epoch 0...\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 0 and indexes from 0 to 500000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 0 and indexes from 500000 to 1000000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 0 and indexes from 1000000 to 1500000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 0 and indexes from 1500000 to 2000000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 0 and indexes from 2000000 to 2500000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 0 and indexes from 2500000 to 3000000\n",
    "Computing new batch...\n",
    "end epoch\n",
    "Writing data to h5 for epoch 0 and indexes from 3000000 to 3309620\n",
    "Epoch 1...\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 1 and indexes from 0 to 500000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 1 and indexes from 500000 to 1000000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 1 and indexes from 1000000 to 1500000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 1 and indexes from 1500000 to 2000000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 1 and indexes from 2000000 to 2500000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 1 and indexes from 2500000 to 3000000\n",
    "Computing new batch...\n",
    "end epoch\n",
    "Writing data to h5 for epoch 1 and indexes from 3000000 to 3309620\n",
    "Epoch 2...\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 2 and indexes from 0 to 500000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 2 and indexes from 500000 to 1000000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 2 and indexes from 1000000 to 1500000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 2 and indexes from 1500000 to 2000000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 2 and indexes from 2000000 to 2500000\n",
    "Computing new batch...\n",
    "Writing data to h5 for epoch 2 and indexes from 2500000 to 3000000\n",
    "Computing new batch...\n",
    "end epoch\n",
    "Writing data to h5 for epoch 2 and indexes from 3000000 to 3309620\n",
    "Writing datasets to disk\n",
    "--- 71815.83514904976 seconds ---\n",
    "RMSE bruit moyen dist absolues : 177.56111\n",
    "RMSE bruit moyen dist relatives : 233.6153\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des données d'entrée du RN et des labels pour le jeu de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_input_RN(test_set_location, test_set_prepared_input_abs_rel_location,\n",
    "                  test_set_labels_abs_location, test_set_labels_rel_location, 3, 500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sortie\n",
    "```\n",
    "Creating input and label sets for ../data/test_set_riken_v2.h5 :\n",
    "Epoch 0...\n",
    "Computing new batch...\n",
    "end epoch\n",
    "Writing data to h5 for epoch 0 and indexes from 0 to 367736\n",
    "Epoch 1...\n",
    "Computing new batch...\n",
    "end epoch\n",
    "Writing data to h5 for epoch 1 and indexes from 0 to 367736\n",
    "Epoch 2...\n",
    "Computing new batch...\n",
    "end epoch\n",
    "Writing data to h5 for epoch 2 and indexes from 0 to 367736\n",
    "Writing datasets to disk\n",
    "--- 7922.944814920425 seconds ---\n",
    "RMSE bruit moyen dist absolues : 177.58287\n",
    "RMSE bruit moyen dist relatives : 233.66093\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
