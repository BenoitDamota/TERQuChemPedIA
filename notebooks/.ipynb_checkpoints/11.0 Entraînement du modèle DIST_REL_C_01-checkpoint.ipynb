{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle DIST_REL_C_01\n",
    "\n",
    "Nous allons ici entraîner un modèle prenant les mêmes entrées et devant prédire les mêmes distances que le modèle DIST_REL_C_RNN_01 (voir notebook 9.2).\n",
    "\n",
    "La différence est que nous allons utiliser un modèle prenant des entrées \"plates\" et qui ne sera pas un RNN. Notre modèle va avoir une topologie très similaire aux différents modèles DELTA_DIST+H.\n",
    "\n",
    "L'objectif ici est de chercher à savoir si l'utilisation des RNN apporte quelque chose ou pas. Nous allons donc entraîner un réseau profond entièrement connecté et comparer les résultats des deux modèles.\n",
    "\n",
    "#### Chemin des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_prepared_input_loc = \"../data/DIST_REL_C_RNN/minimal_prepared_input.h5\"\n",
    "minimal_labels_loc = \"../data/DIST_REL_C_RNN/minimal_labels.h5\"\n",
    "\n",
    "train_prepared_input_loc = \"../data/DIST_REL_C_RNN/train_set_prepared_input.h5\"\n",
    "train_labels_loc = \"../data/DIST_REL_C_RNN/train_set_labels.h5\"\n",
    "\n",
    "models_loc = \"../models/DIST_REL_C_01/11.0/\"\n",
    "logs_loc = \"../models/DIST_REL_C_01/11.0/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des fonctions de coût et de validation\n",
    "\n",
    "#### RMSE (coût)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, targets):\n",
    "    with tf.name_scope(\"rmse_loss\"):\n",
    "        return tf.sqrt(tf.reduce_mean(tf.squared_difference(pred, targets)), name=\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'évaluation des performances (opposé du RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_valid(pred, targets, inputs):\n",
    "    with tf.name_scope(\"rmse_validation\"):\n",
    "        return -rmse(pred, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etudiant/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.optimizers import Adam\n",
    "from tflearn.data_preprocessing import DataPreprocessing\n",
    "import tflearn as tfl\n",
    "import math\n",
    "\n",
    "\n",
    "def creer_RN(epsilon=1e-8, learning_rate=0.001, dropout_val=0.99, stddev_init=0.001,\n",
    "             hidden_act='relu', outlayer_act='prelu', weight_decay=0.001, width=870, depth=3,\n",
    "             validation_fun=rmse_valid, cost_fun=rmse):\n",
    "\n",
    "    # On créé l'initialisateur de tenseur avec une loi normale tronquée. sigma = stddev_init, et les \n",
    "    # valeurs à plus de 2sigma sont re-tirées\n",
    "    winit = tfl.initializations.truncated_normal(stddev=stddev_init, dtype=tf.float32, seed=None)\n",
    "        \n",
    "    # On créé l'input du RN\n",
    "    network = input_data(shape=[None, 870], name='input')\n",
    "    \n",
    "    # On créé les couches cachées\n",
    "    for i in range(depth):\n",
    "        network = fully_connected(network, width, activation=hidden_act, name='fc'+str(i), weights_init=winit,\n",
    "                                  weight_decay=weight_decay)\n",
    "        # On détruit des neurones aléatoirement avec une la probabilité donnée en entrée\n",
    "        network = dropout(network, dropout_val)\n",
    "    \n",
    "    # On ajoute la couche de sortie du réseau\n",
    "    # Fonction d'activation prelu\n",
    "    # Initilisée avec la loi normale tronquée\n",
    "    network = fully_connected(network, 1, activation=outlayer_act, name='outlayer', weights_init=winit)\n",
    "    \n",
    "    adam = Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
    "    \n",
    "    # Couche d'évaluation du modèle. Utilisation d'une descente stochastique Adam\n",
    "    # Learning rate = 0.05\n",
    "    # Loss = fonction définie rmse\n",
    "    network = regression(network, optimizer=adam,\n",
    "    loss=cost_fun, metric=validation_fun, name='target')\n",
    "            \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tflearn as tfl\n",
    "import time\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def train_model(input_X, labels_y, model_name, model_path, logs_path, samples_per_batch=1000, epochs=5,\n",
    "                learning_rate=0.001, epsilon=1e-8, dropout=0.99, stddev_init=0.001, hidden_act='relu',\n",
    "                outlayer_act='prelu', cost_fun=rmse, validation_fun=rmse_valid, width=870, depth=2):\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # On créé le réseau \n",
    "    network = creer_RN(learning_rate=learning_rate, epsilon=epsilon, dropout_val=dropout,\n",
    "                       stddev_init=stddev_init, hidden_act=hidden_act, outlayer_act=outlayer_act,\n",
    "                       validation_fun=validation_fun, cost_fun=cost_fun, width=width, depth=depth)\n",
    "\n",
    "    # On créé le modèle\n",
    "    model = tfl.DNN(network, tensorboard_verbose=3, tensorboard_dir=logs_path)\n",
    "\n",
    "    # Entraînement\n",
    "    model.fit(X_inputs=input_X,Y_targets=labels_y, batch_size=samples_per_batch,\n",
    "              shuffle = True, snapshot_step=100, validation_set=0.1,\n",
    "              show_metric=True, run_id=model_name, n_epoch=epochs)\n",
    "\n",
    "    # Sauvegarde du modèle\n",
    "    model.save(model_path + model_name + \".tflearn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m1456.52966\u001b[0m\u001b[0m | time: 0.103s\n",
      "| Adam | epoch: 009 | loss: 1456.52966 - rmse_validation/Neg: -1456.5297 -- iter: 5000/5071\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m1454.26416\u001b[0m\u001b[0m | time: 1.191s\n",
      "| Adam | epoch: 009 | loss: 1454.26416 - rmse_validation/Neg: -1454.2642 | val_loss: 1345.30920 - val_acc: -1345.3092 -- iter: 5071/5071\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tflearn.data_utils import pad_sequences\n",
    "\n",
    "\n",
    "input_X_h5 = h5py.File(train_prepared_input_loc, 'r')\n",
    "labels_y_h5 = h5py.File(train_labels_loc, 'r')\n",
    "\"\"\"\n",
    "input_X_h5 = h5py.File(minimal_prepared_input_loc, 'r')\n",
    "labels_y_h5 = h5py.File(minimal_labels_loc, 'r')\n",
    "\"\"\"\n",
    "\n",
    "input_X = np.array(input_X_h5[\"inputs\"])\n",
    "input_X = pad_sequences(input_X, dtype=\"float32\", maxlen=870)\n",
    "input_X = input_X.reshape(-1, 870)\n",
    "\n",
    "labels_y = np.array(labels_y_h5[\"targets\"])\n",
    "labels_y = labels_y.reshape(-1, 1)\n",
    "\n",
    "model_name = \"DIST_REL_C_01_basic\"\n",
    "\n",
    "model_path = models_loc\n",
    "logs_path = logs_loc\n",
    "\n",
    "train_model(input_X, labels_y, model_name, model_path, logs_path, samples_per_batch=5000, \n",
    "            epochs=150, learning_rate=0.01, dropout=0.98, epsilon=0.001, hidden_act=\"elu\",\n",
    "            outlayer_act=\"linear\", validation_fun=rmse_valid, cost_fun=rmse,\n",
    "            width=870, depth=3)\n",
    "\n",
    "total_start_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - total_start_time))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
