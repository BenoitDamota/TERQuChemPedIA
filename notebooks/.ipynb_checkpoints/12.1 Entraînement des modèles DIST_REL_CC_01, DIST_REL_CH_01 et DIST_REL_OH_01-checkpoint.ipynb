{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement des modèles DIST_REL_CC_01, DIST_REL_CH_01 et DIST_REL_OH_01\n",
    "\n",
    "Nous allons dans ce notebook entraîner les modèles DIST_REL_CC_01, DIST_REL_CH_01, DIST_REL_OH_01, qui sont une tentative de généralisation de la méthode utilisée pour le modèle DIST_REL_C_01.\n",
    "\n",
    "Ces modèles doivent prédire la distance entre des couples d'atomes (carbone-carbone, carbone-hydrogène, oxygène-hydrogène), en fonction des informations suivantes sur chaque atome de la molécule ne faisant pas partie du couple :\n",
    "\n",
    "* Le numéro atomique (encodé en one-hot-encoding)\n",
    "* La masse atomique\n",
    "* La classe positionnelle de l'atome par rapport à la liaison (voir notebook 9.1)\n",
    "* La distance à chacun des deux atomes de la liaison\n",
    "\n",
    "Le modèle DIST_REL_CC_01 est donc identique au modèle DIST_REL_C_01, à la différence qu'on va l'entraîner sur plus d'exemples.\n",
    "\n",
    "#### Chemin des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle DIST_REL_CC\n",
    "train_CC_prepared_input_loc = \"../data/DIST_REL_CC/train_set_prepared_input.h5\"\n",
    "train_CC_labels_loc = \"../data/DIST_REL_CC/train_set_labels.h5\"\n",
    "minimal_CC_prepared_input_loc = \"../data/DIST_REL_CC/minimal_set_prepared_input.h5\"\n",
    "minimal_CC_labels_loc = \"../data/DIST_REL_CC/minimal_set_labels.h5\"\n",
    "\n",
    "models_CC_loc = \"../models/DIST_REL_CC_01/12.1/\"\n",
    "logs_CC_loc = \"../models/DIST_REL_CC_01/12.1/\"\n",
    "\n",
    "# Modèle DIST_REL_CH\n",
    "train_CH_prepared_input_loc = \"../data/DIST_REL_CH/train_set_prepared_input.h5\"\n",
    "train_CH_labels_loc = \"../data/DIST_REL_CH/train_set_labels.h5\"\n",
    "\n",
    "models_CH_loc = \"../models/DIST_REL_CH_01/12.1/\"\n",
    "logs_CH_loc = \"../models/DIST_REL_CH_01/12.1/\"\n",
    "\n",
    "# Modèle DIST_REL_OH\n",
    "train_OH_prepared_input_loc = \"../data/DIST_REL_OH/train_set_prepared_input.h5\"\n",
    "train_OH_labels_loc = \"../data/DIST_REL_OH/train_set_labels.h5\"\n",
    "\n",
    "models_OH_loc = \"../models/DIST_REL_OH_01/12.1/\"\n",
    "logs_OH_loc = \"../models/DIST_REL_OH_01/12.1/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des fonctions de coût et de validation\n",
    "\n",
    "#### RMSE (coût)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, targets):\n",
    "    with tf.name_scope(\"rmse_loss\"):\n",
    "        return tf.sqrt(tf.reduce_mean(tf.squared_difference(pred, targets)), name=\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'évaluation des performances (opposé du RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_valid(pred, targets, inputs):\n",
    "    with tf.name_scope(\"rmse_validation\"):\n",
    "        return -rmse(pred, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etudiant/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.optimizers import Adam\n",
    "from tflearn.data_preprocessing import DataPreprocessing\n",
    "import tflearn as tfl\n",
    "import math\n",
    "\n",
    "\n",
    "def creer_RN(epsilon=1e-8, learning_rate=0.001, dropout_val=0.99, stddev_init=0.001,\n",
    "             hidden_act='relu', outlayer_act='prelu', weight_decay=0.001, width=870, depth=3,\n",
    "             validation_fun=rmse_valid, cost_fun=rmse, gpu_mem_prop=1):\n",
    "\n",
    "    # On créé l'initialisateur de tenseur avec une loi normale tronquée. sigma = stddev_init, et les \n",
    "    # valeurs à plus de 2sigma sont re-tirées\n",
    "    winit = tfl.initializations.truncated_normal(stddev=stddev_init, dtype=tf.float32, seed=None)\n",
    "    \n",
    "    # On définit la proportion de mémoire utilisée sur le GPU (pour entraîner des modèles en parallèle)\n",
    "    tfl.init_graph(num_cores=16, gpu_memory_fraction=gpu_mem_prop, soft_placement=True)\n",
    "    \n",
    "    # On créé l'input du RN\n",
    "    network = input_data(shape=[None, 870], name='input')\n",
    "    \n",
    "    # On créé les couches cachées\n",
    "    for i in range(depth):\n",
    "        network = fully_connected(network, width, activation=hidden_act, name='fc'+str(i), weights_init=winit,\n",
    "                                  weight_decay=weight_decay)\n",
    "        # On détruit des neurones aléatoirement avec une la probabilité donnée en entrée\n",
    "        network = dropout(network, dropout_val)\n",
    "    \n",
    "    # On ajoute la couche de sortie du réseau\n",
    "    # Fonction d'activation prelu\n",
    "    # Initilisée avec la loi normale tronquée\n",
    "    network = fully_connected(network, 1, activation=outlayer_act, name='outlayer', weights_init=winit)\n",
    "    \n",
    "    adam = Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
    "    \n",
    "    # Couche d'évaluation du modèle. Utilisation d'une descente stochastique Adam\n",
    "    # Learning rate = 0.05\n",
    "    # Loss = fonction définie rmse\n",
    "    network = regression(network, optimizer=adam,\n",
    "    loss=cost_fun, metric=validation_fun, name='target')\n",
    "            \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tflearn as tfl\n",
    "import time\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def train_model(input_X, labels_y, model_name, model_path, logs_path, samples_per_batch=1000, epochs=5,\n",
    "                learning_rate=0.001, epsilon=1e-8, dropout=0.99, stddev_init=0.001, hidden_act='relu',\n",
    "                outlayer_act='prelu', cost_fun=rmse, validation_fun=rmse_valid, width=870, depth=2,\n",
    "                gpu_mem_prop=1):\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # On créé le réseau \n",
    "    network = creer_RN(learning_rate=learning_rate, epsilon=epsilon, dropout_val=dropout,\n",
    "                       stddev_init=stddev_init, hidden_act=hidden_act, outlayer_act=outlayer_act,\n",
    "                       validation_fun=validation_fun, cost_fun=cost_fun, width=width, depth=depth,\n",
    "                       gpu_mem_prop=gpu_mem_prop)\n",
    "\n",
    "    # On créé le modèle\n",
    "    model = tfl.DNN(network, tensorboard_verbose=3, tensorboard_dir=logs_path)\n",
    "\n",
    "    # Entraînement\n",
    "    model.fit(X_inputs=input_X,Y_targets=labels_y, batch_size=samples_per_batch,\n",
    "              shuffle = True, snapshot_step=100, validation_set=0.1,\n",
    "              show_metric=True, run_id=model_name, n_epoch=epochs)\n",
    "\n",
    "    # Sauvegarde du modèle\n",
    "    model.save(model_path + model_name + \".tflearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tflearn.data_utils import pad_sequences\n",
    "\n",
    "\n",
    "def prepare_data_and_train(train_prepared_input_loc, train_labels_loc, model_name, model_path, logs_path,\n",
    "                           gpu_mem_prop=1):\n",
    "    \n",
    "    input_X_h5 = h5py.File(train_prepared_input_loc, 'r')\n",
    "    labels_y_h5 = h5py.File(train_labels_loc, 'r')\n",
    "    \n",
    "    input_X = np.array(input_X_h5[\"inputs\"])\n",
    "    input_X = pad_sequences(input_X, dtype=\"float32\", maxlen=870)\n",
    "    input_X = input_X.reshape(-1, 870)\n",
    "    labels_y = np.array(labels_y_h5[\"targets\"])\n",
    "    labels_y = labels_y.reshape(-1, 1)\n",
    "    \n",
    "    train_model(input_X, labels_y, model_name, model_path, logs_path, samples_per_batch=5000, \n",
    "            epochs=300, learning_rate=0.01, dropout=0.98, epsilon=0.001, hidden_act=\"elu\",\n",
    "            outlayer_act=\"linear\", validation_fun=rmse_valid, cost_fun=rmse,\n",
    "            width=870, depth=3, gpu_mem_prop=gpu_mem_prop)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement de DIST_REL_CC_01 sur le jeu minimal (test d'exécution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: DIST_REL_CC_01_basic\n",
      "Log directory: ../models/DIST_REL_CC_01/12.1/\n",
      "INFO:tensorflow:Summary name rmse_validation/ (raw) is illegal; using rmse_validation/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4500\n",
      "Validation samples: 500\n",
      "--\n",
      "Training Step: 1  | time: 2.145s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - rmse_validation/Neg: 0.0000 | val_loss: 1483.22388 - val_acc: -1483.2239 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m1328.89392\u001b[0m\u001b[0m | time: 1.511s\n",
      "| Adam | epoch: 002 | loss: 1328.89392 - rmse_validation/Neg: -1449.6945 | val_loss: 1483.21375 - val_acc: -1483.2137 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m1449.69446\u001b[0m\u001b[0m | time: 1.505s\n",
      "| Adam | epoch: 003 | loss: 1449.69446 - rmse_validation/Neg: -1449.6945 | val_loss: 1483.20337 - val_acc: -1483.2034 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m1469.82031\u001b[0m\u001b[0m | time: 1.514s\n",
      "| Adam | epoch: 004 | loss: 1469.82031 - rmse_validation/Neg: -1469.8203 | val_loss: 1483.19263 - val_acc: -1483.1926 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m1474.45764\u001b[0m\u001b[0m | time: 1.507s\n",
      "| Adam | epoch: 005 | loss: 1474.45764 - rmse_validation/Neg: -1474.4576 | val_loss: 1483.18066 - val_acc: -1483.1807 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m1475.77551\u001b[0m\u001b[0m | time: 1.518s\n",
      "| Adam | epoch: 006 | loss: 1475.77551 - rmse_validation/Neg: -1475.7755 | val_loss: 1483.16711 - val_acc: -1483.1671 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m1476.20776\u001b[0m\u001b[0m | time: 1.547s\n",
      "| Adam | epoch: 007 | loss: 1476.20776 - rmse_validation/Neg: -1476.2078 | val_loss: 1483.15051 - val_acc: -1483.1505 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m1476.36218\u001b[0m\u001b[0m | time: 1.505s\n",
      "| Adam | epoch: 008 | loss: 1476.36218 - rmse_validation/Neg: -1476.3622 | val_loss: 1483.12891 - val_acc: -1483.1289 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m1476.41699\u001b[0m\u001b[0m | time: 1.524s\n",
      "| Adam | epoch: 009 | loss: 1476.41699 - rmse_validation/Neg: -1476.4170 | val_loss: 1483.09888 - val_acc: -1483.0989 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m1476.43054\u001b[0m\u001b[0m | time: 1.528s\n",
      "| Adam | epoch: 010 | loss: 1476.43054 - rmse_validation/Neg: -1476.4305 | val_loss: 1483.05566 - val_acc: -1483.0557 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m1476.42273\u001b[0m\u001b[0m | time: 1.521s\n",
      "| Adam | epoch: 011 | loss: 1476.42273 - rmse_validation/Neg: -1476.4227 | val_loss: 1482.99280 - val_acc: -1482.9928 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m1476.39941\u001b[0m\u001b[0m | time: 1.531s\n",
      "| Adam | epoch: 012 | loss: 1476.39941 - rmse_validation/Neg: -1476.3994 | val_loss: 1482.90125 - val_acc: -1482.9012 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m1476.36035\u001b[0m\u001b[0m | time: 1.508s\n",
      "| Adam | epoch: 013 | loss: 1476.36035 - rmse_validation/Neg: -1476.3604 | val_loss: 1482.76672 - val_acc: -1482.7667 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m1476.30151\u001b[0m\u001b[0m | time: 1.526s\n",
      "| Adam | epoch: 014 | loss: 1476.30151 - rmse_validation/Neg: -1476.3015 | val_loss: 1482.55444 - val_acc: -1482.5544 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m1476.21570\u001b[0m\u001b[0m | time: 1.522s\n",
      "| Adam | epoch: 015 | loss: 1476.21570 - rmse_validation/Neg: -1476.2157 | val_loss: 1482.03564 - val_acc: -1482.0356 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m1476.08618\u001b[0m\u001b[0m | time: 1.513s\n",
      "| Adam | epoch: 016 | loss: 1476.08618 - rmse_validation/Neg: -1476.0862 | val_loss: 1477.78369 - val_acc: -1477.7837 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m1475.82312\u001b[0m\u001b[0m | time: 1.509s\n",
      "| Adam | epoch: 017 | loss: 1475.82312 - rmse_validation/Neg: -1475.8231 | val_loss: 1449.75500 - val_acc: -1449.7550 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m1474.20654\u001b[0m\u001b[0m | time: 1.589s\n",
      "| Adam | epoch: 018 | loss: 1474.20654 - rmse_validation/Neg: -1474.2065 | val_loss: 1348.84424 - val_acc: -1348.8442 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m1463.94714\u001b[0m\u001b[0m | time: 1.603s\n",
      "| Adam | epoch: 019 | loss: 1463.94714 - rmse_validation/Neg: -1463.9471 | val_loss: 1017.95465 - val_acc: -1017.9547 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m1425.35828\u001b[0m\u001b[0m | time: 1.623s\n",
      "| Adam | epoch: 020 | loss: 1425.35828 - rmse_validation/Neg: -1425.3583 | val_loss: 253.56949 - val_acc: -253.5695 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m1299.05042\u001b[0m\u001b[0m | time: 1.556s\n",
      "| Adam | epoch: 021 | loss: 1299.05042 - rmse_validation/Neg: -1299.0504 | val_loss: 2083.70142 - val_acc: -2083.7014 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m987.73291\u001b[0m\u001b[0m | time: 1.515s\n",
      "| Adam | epoch: 022 | loss: 987.73291 - rmse_validation/Neg: -987.7329 | val_loss: 4456.39648 - val_acc: -4456.3965 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m1291.61865\u001b[0m\u001b[0m | time: 1.545s\n",
      "| Adam | epoch: 023 | loss: 1291.61865 - rmse_validation/Neg: -1291.6187 | val_loss: 6357.53955 - val_acc: -6357.5396 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m2156.40869\u001b[0m\u001b[0m | time: 1.544s\n",
      "| Adam | epoch: 024 | loss: 2156.40869 - rmse_validation/Neg: -2156.4087 | val_loss: 7334.25342 - val_acc: -7334.2534 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m3269.89404\u001b[0m\u001b[0m | time: 1.516s\n",
      "| Adam | epoch: 025 | loss: 3269.89404 - rmse_validation/Neg: -3269.8940 | val_loss: 7285.57910 - val_acc: -7285.5791 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m4309.63770\u001b[0m\u001b[0m | time: 1.535s\n",
      "| Adam | epoch: 026 | loss: 4309.63770 - rmse_validation/Neg: -4309.6377 | val_loss: 6380.18799 - val_acc: -6380.1880 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m5042.93848\u001b[0m\u001b[0m | time: 1.545s\n",
      "| Adam | epoch: 027 | loss: 5042.93848 - rmse_validation/Neg: -5042.9385 | val_loss: 4933.07861 - val_acc: -4933.0786 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m5349.64941\u001b[0m\u001b[0m | time: 1.519s\n",
      "| Adam | epoch: 028 | loss: 5349.64941 - rmse_validation/Neg: -5349.6494 | val_loss: 3290.16235 - val_acc: -3290.1624 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m5229.25293\u001b[0m\u001b[0m | time: 1.544s\n",
      "| Adam | epoch: 029 | loss: 5229.25293 - rmse_validation/Neg: -5229.2529 | val_loss: 1745.16003 - val_acc: -1745.1600 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m4757.70215\u001b[0m\u001b[0m | time: 1.523s\n",
      "| Adam | epoch: 030 | loss: 4757.70215 - rmse_validation/Neg: -4757.7021 | val_loss: 502.56995 - val_acc: -502.5699 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m4056.11182\u001b[0m\u001b[0m | time: 1.523s\n",
      "| Adam | epoch: 031 | loss: 4056.11182 - rmse_validation/Neg: -4056.1118 | val_loss: 444.38153 - val_acc: -444.3815 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m3254.62158\u001b[0m\u001b[0m | time: 1.522s\n",
      "| Adam | epoch: 032 | loss: 3254.62158 - rmse_validation/Neg: -3254.6216 | val_loss: 817.16479 - val_acc: -817.1648 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m2638.09302\u001b[0m\u001b[0m | time: 1.506s\n",
      "| Adam | epoch: 033 | loss: 2638.09302 - rmse_validation/Neg: -2638.0930 | val_loss: 979.04431 - val_acc: -979.0443 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m2247.18799\u001b[0m\u001b[0m | time: 1.517s\n",
      "| Adam | epoch: 034 | loss: 2247.18799 - rmse_validation/Neg: -2247.1880 | val_loss: 1034.77771 - val_acc: -1034.7777 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m1980.69885\u001b[0m\u001b[0m | time: 1.530s\n",
      "| Adam | epoch: 035 | loss: 1980.69885 - rmse_validation/Neg: -1980.6989 | val_loss: 1025.00952 - val_acc: -1025.0095 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m1786.05017\u001b[0m\u001b[0m | time: 1.528s\n",
      "| Adam | epoch: 036 | loss: 1786.05017 - rmse_validation/Neg: -1786.0502 | val_loss: 957.66754 - val_acc: -957.6675 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m1632.68860\u001b[0m\u001b[0m | time: 1.533s\n",
      "| Adam | epoch: 037 | loss: 1632.68860 - rmse_validation/Neg: -1632.6886 | val_loss: 820.37164 - val_acc: -820.3716 -- iter: 4500/4500\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m1499.57861\u001b[0m\u001b[0m | time: 1.514s\n",
      "| Adam | epoch: 038 | loss: 1499.57861 - rmse_validation/Neg: -1368.7506 | val_loss: 582.21741 - val_acc: -582.2174 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m1368.75061\u001b[0m\u001b[0m | time: 1.510s\n",
      "| Adam | epoch: 039 | loss: 1368.75061 - rmse_validation/Neg: -1368.7506 | val_loss: 208.75345 - val_acc: -208.7534 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m1220.93823\u001b[0m\u001b[0m | time: 1.508s\n",
      "| Adam | epoch: 040 | loss: 1220.93823 - rmse_validation/Neg: -1220.9382 | val_loss: 516.43182 - val_acc: -516.4318 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m1035.77002\u001b[0m\u001b[0m | time: 1.517s\n",
      "| Adam | epoch: 041 | loss: 1035.77002 - rmse_validation/Neg: -1035.7700 | val_loss: 1058.15466 - val_acc: -1058.1547 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m941.88751\u001b[0m\u001b[0m | time: 1.511s\n",
      "| Adam | epoch: 042 | loss: 941.88751 - rmse_validation/Neg: -941.8875 | val_loss: 1373.51111 - val_acc: -1373.5111 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m960.39581\u001b[0m\u001b[0m | time: 1.512s\n",
      "| Adam | epoch: 043 | loss: 960.39581 - rmse_validation/Neg: -960.3958 | val_loss: 1407.18518 - val_acc: -1407.1852 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m1029.46362\u001b[0m\u001b[0m | time: 1.534s\n",
      "| Adam | epoch: 044 | loss: 1029.46362 - rmse_validation/Neg: -1029.4636 | val_loss: 1181.20166 - val_acc: -1181.2017 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m1091.24634\u001b[0m\u001b[0m | time: 1.596s\n",
      "| Adam | epoch: 045 | loss: 1091.24634 - rmse_validation/Neg: -1091.2463 | val_loss: 771.12421 - val_acc: -771.1242 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m1104.37549\u001b[0m\u001b[0m | time: 1.537s\n",
      "| Adam | epoch: 046 | loss: 1104.37549 - rmse_validation/Neg: -1104.3755 | val_loss: 284.63980 - val_acc: -284.6398 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m1049.03809\u001b[0m\u001b[0m | time: 1.559s\n",
      "| Adam | epoch: 047 | loss: 1049.03809 - rmse_validation/Neg: -1049.0381 | val_loss: 259.12637 - val_acc: -259.1264 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m926.60144\u001b[0m\u001b[0m | time: 1.514s\n",
      "| Adam | epoch: 048 | loss: 926.60144 - rmse_validation/Neg: -926.6014 | val_loss: 479.71313 - val_acc: -479.7131 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m820.99988\u001b[0m\u001b[0m | time: 1.535s\n",
      "| Adam | epoch: 049 | loss: 820.99988 - rmse_validation/Neg: -820.9999 | val_loss: 561.09387 - val_acc: -561.0939 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m767.25739\u001b[0m\u001b[0m | time: 1.512s\n",
      "| Adam | epoch: 050 | loss: 767.25739 - rmse_validation/Neg: -767.2574 | val_loss: 540.58649 - val_acc: -540.5865 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m734.90417\u001b[0m\u001b[0m | time: 1.513s\n",
      "| Adam | epoch: 051 | loss: 734.90417 - rmse_validation/Neg: -734.9042 | val_loss: 425.98090 - val_acc: -425.9809 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m704.92426\u001b[0m\u001b[0m | time: 1.544s\n",
      "| Adam | epoch: 052 | loss: 704.92426 - rmse_validation/Neg: -704.9243 | val_loss: 207.48679 - val_acc: -207.4868 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m662.98706\u001b[0m\u001b[0m | time: 1.504s\n",
      "| Adam | epoch: 053 | loss: 662.98706 - rmse_validation/Neg: -662.9871 | val_loss: 237.20314 - val_acc: -237.2031 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m596.58069\u001b[0m\u001b[0m | time: 1.525s\n",
      "| Adam | epoch: 054 | loss: 596.58069 - rmse_validation/Neg: -596.5807 | val_loss: 475.75610 - val_acc: -475.7561 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m546.08960\u001b[0m\u001b[0m | time: 1.519s\n",
      "| Adam | epoch: 055 | loss: 546.08960 - rmse_validation/Neg: -546.0896 | val_loss: 534.62927 - val_acc: -534.6293 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m536.08990\u001b[0m\u001b[0m | time: 1.517s\n",
      "| Adam | epoch: 056 | loss: 536.08990 - rmse_validation/Neg: -536.0899 | val_loss: 413.07584 - val_acc: -413.0758 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m536.14386\u001b[0m\u001b[0m | time: 1.516s\n",
      "| Adam | epoch: 057 | loss: 536.14386 - rmse_validation/Neg: -536.1439 | val_loss: 170.17134 - val_acc: -170.1713 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m519.99658\u001b[0m\u001b[0m | time: 1.524s\n",
      "| Adam | epoch: 058 | loss: 519.99658 - rmse_validation/Neg: -519.9966 | val_loss: 212.83505 - val_acc: -212.8351 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m474.09927\u001b[0m\u001b[0m | time: 1.509s\n",
      "| Adam | epoch: 059 | loss: 474.09927 - rmse_validation/Neg: -474.0993 | val_loss: 342.97144 - val_acc: -342.9714 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m439.09525\u001b[0m\u001b[0m | time: 1.513s\n",
      "| Adam | epoch: 060 | loss: 439.09525 - rmse_validation/Neg: -439.0952 | val_loss: 355.59586 - val_acc: -355.5959 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m425.88470\u001b[0m\u001b[0m | time: 1.509s\n",
      "| Adam | epoch: 061 | loss: 425.88470 - rmse_validation/Neg: -425.8847 | val_loss: 266.20258 - val_acc: -266.2026 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m416.14221\u001b[0m\u001b[0m | time: 1.503s\n",
      "| Adam | epoch: 062 | loss: 416.14221 - rmse_validation/Neg: -416.1422 | val_loss: 98.10095 - val_acc: -98.1010 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m396.61609\u001b[0m\u001b[0m | time: 1.518s\n",
      "| Adam | epoch: 063 | loss: 396.61609 - rmse_validation/Neg: -396.6161 | val_loss: 334.81943 - val_acc: -334.8194 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m359.63049\u001b[0m\u001b[0m | time: 1.526s\n",
      "| Adam | epoch: 064 | loss: 359.63049 - rmse_validation/Neg: -359.6305 | val_loss: 539.14148 - val_acc: -539.1415 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m357.36493\u001b[0m\u001b[0m | time: 1.511s\n",
      "| Adam | epoch: 065 | loss: 357.36493 - rmse_validation/Neg: -357.3649 | val_loss: 560.26135 - val_acc: -560.2614 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m379.86533\u001b[0m\u001b[0m | time: 1.522s\n",
      "| Adam | epoch: 066 | loss: 379.86533 - rmse_validation/Neg: -379.8653 | val_loss: 411.67813 - val_acc: -411.6781 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m401.94522\u001b[0m\u001b[0m | time: 1.541s\n",
      "| Adam | epoch: 067 | loss: 401.94522 - rmse_validation/Neg: -401.9452 | val_loss: 155.14827 - val_acc: -155.1483 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m403.72253\u001b[0m\u001b[0m | time: 1.518s\n",
      "| Adam | epoch: 068 | loss: 403.72253 - rmse_validation/Neg: -403.7225 | val_loss: 212.77577 - val_acc: -212.7758 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m375.63391\u001b[0m\u001b[0m | time: 1.513s\n",
      "| Adam | epoch: 069 | loss: 375.63391 - rmse_validation/Neg: -375.6339 | val_loss: 348.97632 - val_acc: -348.9763 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m356.28790\u001b[0m\u001b[0m | time: 1.516s\n",
      "| Adam | epoch: 070 | loss: 356.28790 - rmse_validation/Neg: -356.2879 | val_loss: 372.90247 - val_acc: -372.9025 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m354.75131\u001b[0m\u001b[0m | time: 1.508s\n",
      "| Adam | epoch: 071 | loss: 354.75131 - rmse_validation/Neg: -354.7513 | val_loss: 303.10828 - val_acc: -303.1083 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m356.08392\u001b[0m\u001b[0m | time: 1.589s\n",
      "| Adam | epoch: 072 | loss: 356.08392 - rmse_validation/Neg: -356.0839 | val_loss: 142.61932 - val_acc: -142.6193 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m349.47885\u001b[0m\u001b[0m | time: 1.575s\n",
      "| Adam | epoch: 073 | loss: 349.47885 - rmse_validation/Neg: -349.4789 | val_loss: 198.91922 - val_acc: -198.9192 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m326.51837\u001b[0m\u001b[0m | time: 1.509s\n",
      "| Adam | epoch: 074 | loss: 326.51837 - rmse_validation/Neg: -326.5184 | val_loss: 359.52209 - val_acc: -359.5221 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m313.57709\u001b[0m\u001b[0m | time: 1.502s\n",
      "| Adam | epoch: 075 | loss: 313.57709 - rmse_validation/Neg: -313.5771 | val_loss: 367.15070 - val_acc: -367.1507 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m319.24310\u001b[0m\u001b[0m | time: 1.511s\n",
      "| Adam | epoch: 076 | loss: 319.24310 - rmse_validation/Neg: -319.2431 | val_loss: 235.78722 - val_acc: -235.7872 -- iter: 4500/4500\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m325.05420\u001b[0m\u001b[0m | time: 1.515s\n",
      "| Adam | epoch: 077 | loss: 325.05420 - rmse_validation/Neg: -325.0542 | val_loss: 74.53465 - val_acc: -74.5346 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m316.54111\u001b[0m\u001b[0m | time: 1.507s\n",
      "| Adam | epoch: 078 | loss: 316.54111 - rmse_validation/Neg: -316.5411 | val_loss: 126.57973 - val_acc: -126.5797 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m292.20221\u001b[0m\u001b[0m | time: 1.530s\n",
      "| Adam | epoch: 079 | loss: 292.20221 - rmse_validation/Neg: -292.2022 | val_loss: 105.71915 - val_acc: -105.7191 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m275.09537\u001b[0m\u001b[0m | time: 1.527s\n",
      "| Adam | epoch: 080 | loss: 275.09537 - rmse_validation/Neg: -275.0954 | val_loss: 88.09415 - val_acc: -88.0942 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m257.92120\u001b[0m\u001b[0m | time: 1.537s\n",
      "| Adam | epoch: 081 | loss: 257.92120 - rmse_validation/Neg: -257.9212 | val_loss: 92.68270 - val_acc: -92.6827 -- iter: 4500/4500\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m241.92166\u001b[0m\u001b[0m | time: 1.526s\n",
      "| Adam | epoch: 082 | loss: 241.92166 - rmse_validation/Neg: -241.9217 | val_loss: 79.03479 - val_acc: -79.0348 -- iter: 4500/4500\n",
      "--\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-86c34fe468cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m prepare_data_and_train(minimal_CC_prepared_input_loc, minimal_CC_labels_loc, \"DIST_REL_CC_01_basic\",\n\u001b[0;32m----> 2\u001b[0;31m                        models_CC_loc, logs_CC_loc)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-515282da2fed>\u001b[0m in \u001b[0;36mprepare_data_and_train\u001b[0;34m(train_prepared_input_loc, train_labels_loc, model_name, model_path, logs_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_act\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"elu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moutlayer_act\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_fun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrmse_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_fun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             width=870, depth=3)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4dbc00624494>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(input_X, labels_y, model_name, model_path, logs_path, samples_per_batch, epochs, learning_rate, epsilon, dropout, stddev_init, hidden_act, outlayer_act, cost_fun, validation_fun, width, depth)\u001b[0m\n\u001b[1;32m     27\u001b[0m     model.fit(X_inputs=input_X,Y_targets=labels_y, batch_size=samples_per_batch,\n\u001b[1;32m     28\u001b[0m               \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m               show_metric=True, run_id=model_name, n_epoch=epochs)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Sauvegarde du modèle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[1;32m    204\u001b[0m                          \u001b[0mexcl_trainops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcl_trainops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                          \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                          callbacks=callbacks)\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mretrieve_data_preprocessing_and_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[1;32m    336\u001b[0m                                                        \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                                                        show_metric)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                             \u001b[0;31m# Update training state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_metric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0meval_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_metric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36mevaluate_flow\u001b[0;34m(session, ops_to_evaluate, dataflow)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcurrent_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mfeed_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tflearn/data_flow.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"prepare_data_and_train(minimal_CC_prepared_input_loc, minimal_CC_labels_loc, \"DIST_REL_CC_01_basic\",\n",
    "                       models_CC_loc, logs_CC_loc)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement de DIST_REL_CC_01\n",
    "\n",
    "Dans les faits, les fonctions suivantes seront appelées indépendamment pour que les modèles puissent s'entraîner en parallèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prepare_data_and_train() got an unexpected keyword argument 'gpu_mem_prop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-654bef543cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m prepare_data_and_train(train_CC_prepared_input_loc, train_CC_labels_loc, \"DIST_REL_CC_01_basic\",\n\u001b[0;32m----> 2\u001b[0;31m                        models_CC_loc, logs_CC_loc, gpu_mem_prop=0.28)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: prepare_data_and_train() got an unexpected keyword argument 'gpu_mem_prop'"
     ]
    }
   ],
   "source": [
    "\"\"\"prepare_data_and_train(train_CC_prepared_input_loc, train_CC_labels_loc, \"DIST_REL_CC_01_basic\",\n",
    "                       models_CC_loc, logs_CC_loc, gpu_mem_prop=0.28)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement de DIST_REL_CH_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_and_train(train_CH_prepared_input_loc, train_CH_labels_loc, \"DIST_REL_CH_01_basic\",\n",
    "                       models_CH_loc, logs_CH_loc, gpu_mem_prop=0.31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement de DIST_REL_OH_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"prepare_data_and_train(train_OH_prepared_input_loc, train_OH_labels_loc, \"DIST_REL_OH_01_basic\",\n",
    "                       models_OH_loc, logs_OH_loc, gpu_mem_prop=0.28)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
