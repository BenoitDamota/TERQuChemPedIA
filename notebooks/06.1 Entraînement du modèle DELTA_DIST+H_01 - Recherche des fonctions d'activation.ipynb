{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Entraînement du modèle DELTA_DIST+H_01 - Recherche des fonctions d'activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le but de produire des modèles plus performants, nous allons effectuer une recherche par quadrillage des fonctions d'activation des neurones. Les autres paramètres seront fixés dans un premier temps à des valeurs qui semblent raisonnables.\n",
    "\n",
    "Nous allons donc entraîner plusieurs modèles avec des fonction d'activation qui varient, sur un million d'exemples chacun. Ces exemples seront pris dans les données générées dans le notebook 6.0, c'est à dire des données avec un bruit ajouté correspondant à un déplacement des atomes de l'ordre de 0.3 Å.\n",
    "\n",
    "À moins que les modèles que nous allons créer ici arrêtent d'apprendre très vite, nous n'allons pas les entraîner sur suffisament d'exemples pour avoir une vraie mesure de leurs performances, mais l'observation de la pente de la courbe d'apprentissage pourra nous éclairer sur le meilleur couple de fonctions d'activation.\n",
    "\n",
    "\n",
    "#### Choix des fonctions d'activation\n",
    "\n",
    "Les expérimentations précédentes semblent indiquer que les meilleures fonctions d'activations pour les neurones cachés sont les fonctions de la famille relu. En effet, relu converge plus efficacement que tanh ou les sigmoïdes sur ce problème. Nous allons donc utiliser les fonctions elu, crelu, relu6 et leaky_relu pour les couches cachées et évaluer leurs performances relatives. Notons que nous allons être obligés de réduire la taille du réseau de neurones pour le faire tenir en mémoire de la carte graphique pour utiliser la fonction crelu, car elle nécessite deux fois plus de mémoire.\n",
    "\n",
    "Pour la couche de sortie, nous utiliserons uniquement la fonction linéaire de pente 1, car il s'agit d'une tâche de régression (voir https://stats.stackexchange.com/questions/218542/which-activation-function-for-output-layer)\n",
    "\n",
    "\n",
    "#### Analyse des résultats\n",
    "\n",
    "Toutes les fonctions que l'on a testé ici semblent avoir des performances comparables et convergent toutes vers une loss de 107 environ. Les différences sont sur la stabilité des résultats. Les fonctions elu et relu6 sont les plus stables, elles convergent rapidement vers la loss minimale et ne font pas des bonds vers des loss plus élevées durant l'entraînement. La fonction leaky_relu est légèrement plus instable et la fonction crelu fait des bonds plus réguliers vers des loss plus importantes. Cela peut également être expliqué par le fait que le réseau utilisé sur le test de crelu était de taille moins importante. Les scores de validation sont eux aussi comparables, seuls ceux de crelu sont significativement moins bons.\n",
    "\n",
    "Pour l'entraînement des réseaux suivants, nous allons donc utiliser en priorité la fonction elu pour la rapidité de sa convergence et sa stabilité, mais nous testerons également la fonction leaky_relu si les résultats sont peu probants, car son léger manque de stabilité pourra peut-être nous sortir de minimums locaux lors de la descente de gradient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chemin des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_prepared_input_loc = \"../data/minimal_set_riken_v2_prepared_input_bruit+.h5\"\n",
    "minimal_labels_loc = \"../data/minimal_set_riken_v2_labels_bruit+.h5\"\n",
    "\n",
    "train_prepared_input_loc = \"../data/train_set_riken_v2_prepared_input_bruit+.h5\"\n",
    "train_labels_loc = \"../data/train_set_riken_v2_labels_bruit+.h5\"\n",
    "\n",
    "mini_prepared_input_loc = \"../data/mini_set_prepared_input_bruit+.h5\"\n",
    "mini_labels_loc = \"../data/mini_set_labels_bruit+.h5\"\n",
    "\n",
    "\n",
    "models_loc = \"../models/DELTA_DIST+H_01/6.1.FONCTIONS_ACT/models/\"\n",
    "logs_loc = \"../models/DELTA_DIST+H_01/6.1.FONCTIONS_ACT/logs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du RN\n",
    "\n",
    "### Fonctions de coût et d'évaluation du modèle\n",
    "\n",
    "Les fonctions ci-dessous sont très fortement inspirées du travail de Nicolas Roux lors de son TER de M1 en 2017. Les différences sont les suivantes.\n",
    "\n",
    "* Calcul du RMSE uniquement sur les atomes définis\n",
    "* Utilisation d'un score R2 pour la validation\n",
    "* Recherche par quadrillage des hyper-paramètres\n",
    "\n",
    "#### Fonction renvoyant le masque des atomes à prendre en compte pour les calculs\n",
    "\n",
    "L'entrée et la sortie du RN étant définies par une méthode de padding, seul un certain nombre d'entrées et de sortie est utilisé pour chaque exemple d'entraînement en fonction du nombre d'atomes de la molécule. On définit ici une fonction qui renvoie le masque des différences de distances à prendre en compte sur les données en entrée et les étiquettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def calcul_masque_atomes_definis(targets):\n",
    "    \"\"\" On calcule le masque booléen des atomes donnés en entrée du RN en fonction du vecteur targets\"\"\"\n",
    "    \n",
    "    # On cherche à obtenir un masque booléen des atomes définis en entrée. Pour cela, on prend en entrée\n",
    "    # les étiquettes sous la forme d'une matrice (200, 4) dont chaque ligne i est la distance de l'atome i avec\n",
    "    # les atomes fictifs du repère. L'atome est indéfini ssi. la somme de la ligne est nulle. En effet,\n",
    "    # un atome défini ne peut pas avoir une distance nulle avec les quatre atomes fictifs, et on veille\n",
    "    # à ce que le vecteurs targets ne contienne que des valeurs nulles pour les atomes non définis.\n",
    "    # On obtient donc un masque booléen de tous les atomes définis en entrée\n",
    "    \n",
    "    ## On somme les distances de chaque atome ##\n",
    "    targets_dists_sums = tf.reduce_sum(targets, 1)\n",
    "    \n",
    "    ## On créé le masque des sommes différentes de zéro ##\n",
    "    \n",
    "    # Création des matrice de True et de False de la dimension de la matrice des sommes (nécessaires\n",
    "    # pour tf.where)\n",
    "    zeros = tf.cast(tf.zeros_like(targets_dists_sums),dtype=tf.bool)\n",
    "    ones = tf.cast(tf.ones_like(targets_dists_sums),dtype=tf.bool)\n",
    "    \n",
    "    return tf.where(targets_dists_sums>0, ones, zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de coût"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_rmse(predictions, targets):\n",
    "    \"\"\" Calcule le RMSE partiel des prédictions par rapport aux valeurs attendues. Le RMSE est partiel car\n",
    "    on ne le calcule que pour les sorties correspondant aux atomes donnés en entrée. En d'autres\n",
    "    termes, on ne pousse pas le modèle à donner des distances nulles pour les atomes indéfinis\n",
    "    en entrée\"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"partial_rmse\"):\n",
    "\n",
    "        # On met les prédictions et les cibles sous la forme d'une matrice (200, 4)\n",
    "        predictions = tf.reshape(predictions, [-1, 4])\n",
    "        targets = tf.reshape(targets, [-1, 4])\n",
    "\n",
    "        # On calcule le masque des atomes définis selon les cibles\n",
    "        defined_atoms_mask = calcul_masque_atomes_definis(targets)\n",
    "        \n",
    "        # On masque les prédictions et les étiquettes selon le masque des atomes définis\n",
    "        targets_masked = tf.boolean_mask(targets, defined_atoms_mask)\n",
    "        predictions_masked = tf.boolean_mask(predictions, defined_atoms_mask)   \n",
    "\n",
    "        return tf.sqrt(tf.reduce_mean(tf.squared_difference(predictions_masked, targets_masked)), name=\"rmse\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'évaluation des performances (score R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_r2_score(predictions, targets, inputs):\n",
    "    \"\"\" Renvoie le score R2 de la prédiction (le calcul est effectué uniquement sur les résultats\n",
    "    des atomes donnés en entrée) \"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"partial_r2\"):\n",
    "    \n",
    "        # On met les prédictions et les cibles sous la forme d'une matrice (200, 4)\n",
    "        predictions = tf.reshape(predictions, [-1, 4])\n",
    "        targets = tf.reshape(targets, [-1, 4])\n",
    "\n",
    "        # On calcule le masque des atomes définis selon les cibles\n",
    "        defined_atoms_mask = calcul_masque_atomes_definis(targets)\n",
    "\n",
    "        # On masque les prédictions et les étiquettes selon le masque des atomes définis\n",
    "        targets_masked = tf.boolean_mask(targets, defined_atoms_mask)\n",
    "        predictions_masked = tf.boolean_mask(predictions, defined_atoms_mask)\n",
    "\n",
    "        # Calcul de l'erreur totale\n",
    "        total_error = tf.reduce_sum(tf.square(tf.subtract(targets, tf.reduce_mean(targets_masked))))\n",
    "\n",
    "        # Calcul de l'erreur inexpliquée\n",
    "        unexplained_error = tf.reduce_sum(tf.square(tf.subtract(targets_masked, predictions_masked)))\n",
    "\n",
    "        r2 = tf.subtract(1.0, tf.divide(unexplained_error, total_error), \"r2_score\")\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition d'une fonction créant le RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.optimizers import Adam\n",
    "from tflearn.data_preprocessing import DataPreprocessing\n",
    "import math\n",
    "\n",
    "\n",
    "def creer_1k_3x10k_800(epsilon=1e-8, learning_rate=0.001, dropout_val=0.99, stddev_init=0.001,\n",
    "                      hidden_act='relu', outlayer_act='prelu'):\n",
    "    \"\"\" Fonction créant un réseau de neurones de type fully connected, ayant une couche d'entrée de 1000\n",
    "    neurones, quatre couches cachées de 8650 neurones et une sortie de 800 neurones\n",
    "    Inputs : hyperparamètres\n",
    "    \"\"\"\n",
    "\n",
    "    # On créé l'initialisateur de tenseur avec une loi normale tronquée. sigma = stddev_init, et les \n",
    "    # valeurs à plus de 2sigma sont re-tirées\n",
    "    winit = tfl.initializations.truncated_normal(stddev=stddev_init, dtype=tf.float32, seed=None)\n",
    "    \n",
    "    # On créé l'input du RN\n",
    "    network = input_data(shape=[None, 1000], name='input')\n",
    "    \n",
    "    # crelu ayant besoin de tenseurs deux fois plus importants, on adapte la taille du modèle\n",
    "    if hidden_act == 'crelu':\n",
    "        depth = 2\n",
    "        width = 8000\n",
    "    else:\n",
    "        depth = 3\n",
    "        width = 10000\n",
    "    \n",
    "    # On créé les couches cachées\n",
    "    for i in range(depth):\n",
    "        network = fully_connected(network, width, activation=hidden_act, name='fc'+str(i), weights_init=winit)\n",
    "        # On détruit des neurones aléatoirement avec une la probabilité donnée en entrée\n",
    "        network = dropout(network, dropout_val)\n",
    "    \n",
    "    # On ajoute la couche de sortie du réseau\n",
    "    # Fonction d'activation prelu\n",
    "    # Initilisée avec la loi normale tronquée\n",
    "    network = fully_connected(network, 800, activation=outlayer_act, name='outlayer', weights_init=winit)\n",
    "    \n",
    "    adam = Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
    "    \n",
    "    # Couche d'évaluation du modèle. Utilisation d'une descente stochastique Adam\n",
    "    # Learning rate = 0.05\n",
    "    # Loss = fonction définie rmse\n",
    "    network = regression(network, optimizer=adam,\n",
    "    loss=partial_rmse, metric=partial_r2_score, name='target')\n",
    "            \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "\n",
    "\n",
    "#### Fonction renvoyant deux sous-ensembles du jeu d'entrainement : un ensemble d'exemples et les cibles correspondantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(train_set, targets, reduce_train_fold_size):\n",
    "    \"\"\" Permet d'obtenir un sous-ensemble du jeu d'entraînement afin de ne pas travailler sur le jeu\n",
    "    d'entraînement total pour la recherche par quadrillage et donc de gagner du temps d'exécution. L'idée\n",
    "    et que si un ensemble d'hyper-paramètres produit des meilleurs résultats que les autres ensembles\n",
    "    d'hyper-paramètres sur l'ensemble du jeu d'entraînement, alors on suppose que ce sera également \n",
    "    le cas sur une partie des données. \"\"\"\n",
    "\n",
    "    return (train_set[\"inputs\"][:reduce_train_fold_size], targets[\"targets\"][:reduce_train_fold_size])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement des modèles\n",
    "\n",
    "#### Fonction d'entraînement d'un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tflearn as tfl\n",
    "import time\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def train_model(input_X, labels_y, model_name, model_path, logs_path, samples_per_batch=1000, epochs=5,\n",
    "                learning_rate=0.001, epsilon=1e-8, dropout=0.99, stddev_init=0.001, hidden_act='relu',\n",
    "                outlayer_act='prelu'):\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # On créé le réseau \n",
    "    network = creer_1k_3x10k_800(learning_rate=learning_rate, epsilon=epsilon, dropout_val=dropout,\n",
    "                                 stddev_init=stddev_init, hidden_act=hidden_act, outlayer_act=outlayer_act)\n",
    "\n",
    "    # On créé le modèle\n",
    "    model = tfl.DNN(network, tensorboard_verbose=3, tensorboard_dir=logs_path)\n",
    "\n",
    "    # Entraînement\n",
    "    model.fit(X_inputs=input_X,Y_targets=labels_y, batch_size=samples_per_batch,\n",
    "              shuffle = True, snapshot_step=10000, validation_set=0.1,\n",
    "              show_metric=True, run_id=model_name , n_epoch=epochs)\n",
    "\n",
    "    # Sauvegarde du modèle\n",
    "    #model.save(model_path + model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recherche par quadrillage du meilleur couple de fonctions d'activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_validation_fun(input_X, labels_y, model_path, logs_path, hiddenlayers_functions, outlayer_functions):\n",
    "    \n",
    "    for hidden_fun in hiddenlayers_functions:\n",
    "        for outlayer_function in outlayer_functions:\n",
    "            \n",
    "            model_name = \"hidden\"+hidden_fun+\"_oulayer\"+outlayer_function+\"/\"\n",
    "            model_path = model_path+model_name+\"/\"\n",
    "            logs_path = logs_path+model_name+\"/\"\n",
    "            \n",
    "            train_model(input_X, labels_y, model_name, model_path, logs_path, samples_per_batch=1000, \n",
    "                        epochs=1, learning_rate=0.01, dropout=0.95, epsilon=0.001, hidden_act=hidden_fun,\n",
    "                       outlayer_act=outlayer_function)\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: hiddenelu_oulayerlinear/\n",
      "Log directory: ../models/DELTA_DIST+H_01/6.1.FONCTIONS_ACT/logs/hiddenelu_oulayerlinear//\n",
      "INFO:tensorflow:Summary name partial_r2/ (raw) is illegal; using partial_r2/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 5\n",
      "Validation samples: 1\n",
      "--\n",
      "Training Step: 1  | time: 1.355s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - partial_r2/r2_score: 0.0000 | val_loss: 161.80377 - val_acc: 0.8633 -- iter: 5/5\n",
      "--\n",
      "---------------------------------\n",
      "Run id: hiddenselu_oulayerlinear/\n",
      "Log directory: ../models/DELTA_DIST+H_01/6.1.FONCTIONS_ACT/logs/hiddenelu_oulayerlinear//hiddenselu_oulayerlinear//\n",
      "INFO:tensorflow:Summary name partial_r2/ (raw) is illegal; using partial_r2/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 5\n",
      "Validation samples: 1\n",
      "--\n",
      "Training Step: 1  | time: 1.354s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - partial_r2/r2_score: 0.0000 | val_loss: 211.16464 - val_acc: 0.9069 -- iter: 5/5\n",
      "--\n",
      "---------------------------------\n",
      "Run id: hiddencrelu_oulayerlinear/\n",
      "Log directory: ../models/DELTA_DIST+H_01/6.1.FONCTIONS_ACT/logs/hiddenelu_oulayerlinear//hiddenselu_oulayerlinear//hiddencrelu_oulayerlinear//\n",
      "INFO:tensorflow:Summary name partial_r2/ (raw) is illegal; using partial_r2/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 5\n",
      "Validation samples: 1\n",
      "--\n",
      "Training Step: 1  | time: 1.392s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - partial_r2/r2_score: 0.0000 | val_loss: 220.66719 - val_acc: 0.9369 -- iter: 5/5\n",
      "--\n",
      "---------------------------------\n",
      "Run id: hiddenrelu6_oulayerlinear/\n",
      "Log directory: ../models/DELTA_DIST+H_01/6.1.FONCTIONS_ACT/logs/hiddenelu_oulayerlinear//hiddenselu_oulayerlinear//hiddencrelu_oulayerlinear//hiddenrelu6_oulayerlinear//\n",
      "INFO:tensorflow:Summary name partial_r2/ (raw) is illegal; using partial_r2/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 5\n",
      "Validation samples: 1\n",
      "--\n",
      "Training Step: 1  | time: 1.331s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - partial_r2/r2_score: 0.0000 | val_loss: 211.18295 - val_acc: 0.9069 -- iter: 5/5\n",
      "--\n",
      "---------------------------------\n",
      "Run id: hiddenleaky_relu_oulayerlinear/\n",
      "Log directory: ../models/DELTA_DIST+H_01/6.1.FONCTIONS_ACT/logs/hiddenelu_oulayerlinear//hiddenselu_oulayerlinear//hiddencrelu_oulayerlinear//hiddenrelu6_oulayerlinear//hiddenleaky_relu_oulayerlinear//\n",
      "INFO:tensorflow:Summary name partial_r2/ (raw) is illegal; using partial_r2/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 5\n",
      "Validation samples: 1\n",
      "--\n",
      "Training Step: 1  | time: 1.380s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - partial_r2/r2_score: 0.0000 | val_loss: 142.60681 - val_acc: 0.9538 -- iter: 5/5\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "hiddenlayers_functions = ['elu', 'crelu', 'relu6', 'leaky_relu']\n",
    "outlayer_functions = ['linear']\n",
    "\n",
    "\"\"\"input_X_h5 = h5py.File(train_prepared_input_loc, 'r')\n",
    "labels_y_h5 = h5py.File(train_labels_loc, 'r')\"\"\"\n",
    "\n",
    "input_X_h5 = h5py.File(mini_prepared_input_loc, 'r')\n",
    "labels_y_h5 = h5py.File(mini_labels_loc, 'r')\n",
    "\n",
    "input_X, labels_y = get_fold(input_X_h5, labels_y_h5, 3000000)\n",
    "\n",
    "grid_search_validation_fun(input_X, labels_y, models_loc, logs_loc,\n",
    "                           hiddenlayers_functions, outlayer_functions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
