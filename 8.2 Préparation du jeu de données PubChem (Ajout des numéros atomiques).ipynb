{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation du jeu de données PubChem (Ajout des numéros atomiques)\n",
    "\n",
    "Pour tenter d'améliorer les performances des RN que nous entraînons, nous allons rajouter des informations en entrée. La géométrie des molécules dépendant du nuage électronique, qui dépend entre autres du nombre d'électrons, nous allons ajouter le numéro atomique des atomes en entrée des RN, pour leur éviter d'avoir à créer implicitement une \"table de correspondances\" entre les masses atomiques déjà fournies et les numéros atomiques.\n",
    "\n",
    "Dans le même temps, nous allons travailler sur le jeu de données réduit créé dans le notebook 8.0, contenant uniquement les molécules de taille comprise entre 2 et 60, car les données sur les autres molécules sont soit aberrantes pour la tâche que nous effectuons, soit marginales en représentation. Cela va nous permettre de créer des jeux de données d'entrée et de cible pour les RN moins importants et donc de gagner en mémoire et en temps d'exécution.\n",
    "\n",
    "Pour chaque molécule, nous allons donc créer une entrée du RN contenant pour chaque atome les quatre informations de position, la masse atomique et le numéro atomique. Cela revient donc à 60\\*6 nombres soit 360 nombres plutôt que 1000 comme c'était le cas jusqu'ici.\n",
    "\n",
    "Pour chaque molécule, nous allons également créer un vecteur cible contenant les informations sur les différences de distances attendues sur les quatre informations de position. Cela revient donc à 60\\*4 valeurs soit 240 plutôt que 800 comme c'était le cas jusqu'ici.\n",
    "\n",
    "De plus, nous allons convertir les données concernant les distances en entrée du RN en mÅ, dans l'idée qu'il sera peut être plus simple pour les RN d'effectuer des prédictions correctes si les données d'entrée et de sortie sont dans le même ordre de grandeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_location = \"../data/test_set_riken_v2_reduced.h5\"\n",
    "test_set_prepared_input_location = \"../data/test_set_riken_v2_prepared_input_bruit+_anums_reduced.h2\"\n",
    "test_set_labels_location = \"../data/test_set_riken_v2_labels_bruit+_anums_reduced.h2\"\n",
    "\n",
    "train_set_location = \"../data/train_set_riken_v2_reduced.h5\"\n",
    "train_set_prepared_input_location = \"../data/train_set_riken_v2_prepared_input_bruit+_anums_reduced.h5\"\n",
    "train_set_labels_location = \"../data/train_set_riken_v2_labels_bruit+_anums_reduced.h5\"\n",
    "\n",
    "minimal_set_riken_location = \"../data/minimal_set_riken_v2_reduced.h5\"\n",
    "minimal_set_prepared_input_location = \"../data/minimal_set_riken_v2_prepared_input_bruit+_anums_reduced.h5\"\n",
    "minimal_set_labels_location = \"../data/minimal_set_riken_v2_labels_bruit+_anums_reduced.h5\"\n",
    "\n",
    "mini_set_riken_location = \"../data/mini_set.h5\"\n",
    "mini_set_prepared_input_location = \"../data/mini_set_prepared_input_bruit+_anums_reduced.h5\"\n",
    "mini_set_labels_location = \"../data/mini_set_labels_bruit+_anums_reduced.h5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction d'ajout de bruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def positions_bruitees(positions):    \n",
    "    bruit = np.random.normal(loc=0.0, scale=0.1732, size=positions.shape)\n",
    "    return ((positions + bruit), bruit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction de calcul de la matrice de distances aux points du repère fixes compressée à partir de la matrice des coordonnées des atomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_distances_compr_abs(positions):\n",
    "    \"\"\" Renvoie la matrice de distances compressée des positions des atomes passées en paramètres\n",
    "    La matrice de distances compressée est définie de la façon suivante : pour chaque atome, on calcule\n",
    "    la distance avec chaque point du repère. Une ligne i de la matrice (n,4) correspond aux distances\n",
    "    de l'atome i avec chacun des quatre points du repère\"\"\"\n",
    "    \n",
    "    nb_at = len(positions)\n",
    "    \n",
    "    # On renvoie un tableau vide si la molécule est vide\n",
    "    if nb_at == 0:\n",
    "        return []\n",
    "    \n",
    "    repere = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    repere = np.vstack([repere]*nb_at)\n",
    "\n",
    "    positions = np.tile(positions, 4).reshape(4*nb_at, 3)\n",
    "    \n",
    "    return np.sqrt(np.sum(np.power(positions-repere, 2), 1)).reshape(nb_at, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de création des entrées et des labels des RN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def creation_input_RN(set_location, input_rn_location_rel_abs, labels_location, epochs, nb_mol_mem):\n",
    "    \n",
    "    \"\"\" nb_mol_mem est le nombre maximal de molécules que l'on stocke simultanément en mémoire. Lorsque la \n",
    "    taille est atteinte, on écrit les entrées du RN et les cibles du RN sur le disque (taille max des\n",
    "    batchs de traitement) \n",
    "    La nécessité d'utiliser des batchs de traitement en mémoire est due au fait que le traitement devient très\n",
    "    long si on ne met pas de données en mémoire et qu'on écrit sur le disque à chaque itération. En utilisant\n",
    "    les batchs, l'écriture sur le disque se fait en bloc.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()    \n",
    "    mol_vides = 0\n",
    "    \n",
    "    rmse_epochs = []\n",
    "    \n",
    "    print(\"Creating input and label sets for \"+set_location+\" : \")\n",
    "\n",
    "    # On charge le jeu de données original (en lecture seule)\n",
    "    original_dataset_h5 = h5py.File(set_location, 'r')\n",
    "    \n",
    "    # On enregistre la taille du jeu de données\n",
    "    taille = len(original_dataset_h5[\"anums\"])\n",
    "    \n",
    "    # On créé les jeux de données d'entrée du RN et de labels\n",
    "    input_rn_dataset_h5 = h5py.File(input_rn_location_rel_abs, 'w')\n",
    "    labels_dataset_h5 = h5py.File(labels_location, 'w')\n",
    "\n",
    "    # On créé les datasets inputs et targets \n",
    "    input_dataset = input_rn_dataset_h5.create_dataset(\"inputs\", shape=(epochs*taille, 360),\n",
    "                                       dtype=np.float32, compression=\"gzip\", \n",
    "                                       chunks=True)\n",
    "\n",
    "    targets_dataset = labels_dataset_h5.create_dataset(\"targets\", shape=(epochs*taille, 240),\n",
    "                                       dtype=np.float32, compression=\"gzip\", \n",
    "                                       chunks=True)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            \n",
    "            print(\"Epoch \"+str(k)+\"...\")\n",
    "\n",
    "            # Contient les rmse de tous les bruits ajoutés à chaque molécule durant toute l'époque de génération\n",
    "            # de l'entrée du RN. À la fin de l'époque, on en fait la moyenne et on l'ajoute à rmse_epochs\n",
    "            bruits_epoch_rmse = np.empty(shape=(taille,), dtype=np.float32)\n",
    "           \n",
    "            # On créé les tableaux np de valeurs du jeu original pour l'époque courante\n",
    "            input_coords = np.array(original_dataset_h5[\"riken_coords\"])\n",
    "            input_masses = np.array(original_dataset_h5[\"amasses\"])\n",
    "            input_nums = np.array(original_dataset_h5[\"anums\"])\n",
    "            \n",
    "            # Indice de la première molécule traitée du batch courant (non défni pour le moment)\n",
    "            indice_batch_courant = None\n",
    "            \n",
    "            # On parcourt toutes les molécules\n",
    "            for i in range(taille):\n",
    "\n",
    "                # On arrive au début d'un nouveau batch de traitement\n",
    "                if i%nb_mol_mem == 0:\n",
    "                    \n",
    "                    # On écrit les données du batch précédent sur le disque s'il existe un batch précédent\n",
    "                    if indice_batch_courant is not None :\n",
    "                        print(\"Writing data to h5 for epoch \"+str(k)+\" and indexes from \"+\n",
    "                              str(indice_batch_courant)+\" to \"+str(indice_batch_courant+taille_batch_courant))\n",
    "                        \n",
    "                        input_dataset[k*taille+indice_batch_courant: \n",
    "                                      k*taille+indice_batch_courant+taille_batch_courant] = np_input_dataset\n",
    "                        \n",
    "                        targets_dataset[k*taille+indice_batch_courant: \n",
    "                                         k*taille+indice_batch_courant+taille_batch_courant] = np_targets_dataset\n",
    "                   \n",
    "                        \n",
    "                    # On met à jour la première molécule du batch courant\n",
    "                    if indice_batch_courant is None :\n",
    "                        indice_batch_courant = 0\n",
    "                    else:\n",
    "                        indice_batch_courant += nb_mol_mem\n",
    "                    \n",
    "                    # On calcule la taille du nouveau batch\n",
    "                    taille_batch_courant = min(nb_mol_mem, taille - i)\n",
    "                    \n",
    "                    print(\"Computing new batch...\")\n",
    "                        \n",
    "                    # On créé les nouveaux tableaux en mémoire du batch courant\n",
    "                    np_input_dataset = np.empty(shape=(taille_batch_courant, 360))\n",
    "                    np_targets_dataset = np.empty(shape=(taille_batch_courant, 240))\n",
    "                                   \n",
    "                # On récupère les coordonnées de la molécule courante\n",
    "                coords = np.array(input_coords[i]).reshape(-1,3)\n",
    "                \n",
    "                # On calcule les matrices de distances aux points fixes en mÅ\n",
    "                dist_init = matrice_distances_compr_abs(coords)*1000\n",
    "                \n",
    "                # On insère le bruit sur les coordonnées\n",
    "                coords_bruit, bruit = positions_bruitees(coords)\n",
    "                coords_bruit = coords_bruit.reshape(-1, 3)\n",
    "\n",
    "                # On calcule les différence de distances cibles (en mÅ) et les distances bruitées (en mÅ),\n",
    "                # pour les distances relatives et absolues\n",
    "                dist_bruit = matrice_distances_compr_abs(coords_bruit)*1000\n",
    "                delta_dist_targets = (dist_init - dist_bruit)\n",
    "\n",
    "                # On récupère les masses atomiques de la molécule courante\n",
    "                masses = input_masses[i]\n",
    "                anums = input_nums[i]\n",
    "\n",
    "                # On initialise l'entrée du RN et le vecteur cible pour la molécule courante\n",
    "                entree_courante = np.zeros(shape=(360, 1))\n",
    "                cible_courante = np.zeros(shape=(60, 4))\n",
    "\n",
    "                # On ajoute les coordonnées bruitées et les masses à l'entrée avec padding, et les coordonnées\n",
    "                # cibles au dataset targets\n",
    "                for j in range(len(masses)):\n",
    "\n",
    "                    # Ajout des distances absolues, des distances relatives et de la masse au vecteur entrée\n",
    "                    index_input_courant = j*6\n",
    "                    entree_courante[index_input_courant:index_input_courant+4] = dist_bruit[j].reshape(4,1)\n",
    "                    entree_courante[index_input_courant+4] = masses[j]\n",
    "                    entree_courante[index_input_courant+5] = anums[j]\n",
    "\n",
    "                    # Ajout des données aux matrices cible\n",
    "                    cible_courante[j] = delta_dist_targets[j]\n",
    "\n",
    "\n",
    "                # On aplatit les matrices cible\n",
    "                cible_courante = cible_courante.reshape(1, 240)\n",
    "\n",
    "                # On insère les données dans le tableau np en mémoire\n",
    "                np_input_dataset[i%taille_batch_courant] = entree_courante.reshape(1, 360)\n",
    "                np_targets_dataset[i%taille_batch_courant] = cible_courante\n",
    "\n",
    "                # On ajoute le rmse ajouté à la molécule au tableau des rmse de l'époque\n",
    "                np_delta_dist_targets = np.array(delta_dist_targets)\n",
    "                bruits_epoch_rmse[i] = np.sqrt(np.mean(np.square(np_delta_dist_targets)))\n",
    "                \n",
    "            \n",
    "            \n",
    "            print(\"end epoch\")\n",
    "            # On ajoute les données du dernier batch\n",
    "            print(\"Writing data to h5 for epoch \"+str(k)+\" and indexes from \"+\n",
    "                              str(indice_batch_courant)+\" to \"+str(indice_batch_courant+taille_batch_courant))\n",
    "                        \n",
    "            input_dataset[k*taille+indice_batch_courant: \n",
    "                          k*taille+indice_batch_courant+taille_batch_courant] = np_input_dataset\n",
    "\n",
    "            targets_dataset[k*taille+indice_batch_courant: \n",
    "                                k*taille+indice_batch_courant+taille_batch_courant] = np_targets_dataset\n",
    "    \n",
    "                \n",
    "            # On ajoute le rmse moyen de l'époque au tableau des rmse de toutes les époques\n",
    "            rmse_epochs.append(np.mean(bruits_epoch_rmse))\n",
    "            \n",
    "\n",
    "        print(\"Writing datasets to disk\")\n",
    "        input_rn_dataset_h5.flush()\n",
    "        labels_dataset_h5.flush()\n",
    "\n",
    "        \n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        # On calcule le rmse moyen de toutes les époques\n",
    "        np_rmse_epochs = np.array(rmse_epochs)\n",
    "        print(\"RMSE bruit moyen dist : \"+str(np.mean(np_rmse_epochs)))\n",
    "\n",
    "        \n",
    "    finally:\n",
    "        original_dataset_h5.close()\n",
    "        input_rn_dataset_h5.close()\n",
    "        labels_dataset_h5.close()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input and label sets for ../data/mini_set.h5 : \n",
      "Epoch 0...\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 0 to 1\n",
      "Computing new batch...\n",
      "end epoch\n",
      "Writing data to h5 for epoch 0 and indexes from 1 to 2\n",
      "Writing datasets to disk\n",
      "--- 0.007700204849243164 seconds ---\n",
      "RMSE bruit moyen dist : 181.44357\n"
     ]
    }
   ],
   "source": [
    "#creation_input_RN(mini_set_riken_location, mini_set_prepared_input_location, mini_set_labels_location, 1,\n",
    "#                 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input and label sets for ../data/minimal_set_riken_v2_reduced.h5 : \n",
      "Epoch 0...\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 0 to 1000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 1000 to 2000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 2000 to 3000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 3000 to 4000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 4000 to 5000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 5000 to 6000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 6000 to 7000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 7000 to 8000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 8000 to 9000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 9000 to 10000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 10000 to 11000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 11000 to 12000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 12000 to 13000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 13000 to 14000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 14000 to 15000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 15000 to 16000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 16000 to 17000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 17000 to 18000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 18000 to 19000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 19000 to 20000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 20000 to 21000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 21000 to 22000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 22000 to 23000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 23000 to 24000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 24000 to 25000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 25000 to 26000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 26000 to 27000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 27000 to 28000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 28000 to 29000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 29000 to 30000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 30000 to 31000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 31000 to 32000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 32000 to 33000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 33000 to 34000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 34000 to 35000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 35000 to 36000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 36000 to 37000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 37000 to 38000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 38000 to 39000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 39000 to 40000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 40000 to 41000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 41000 to 42000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 42000 to 43000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 43000 to 44000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 44000 to 45000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 45000 to 46000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 46000 to 47000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 47000 to 48000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 48000 to 49000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 49000 to 50000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 50000 to 51000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 51000 to 52000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 52000 to 53000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 53000 to 54000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 54000 to 55000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 55000 to 56000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 56000 to 57000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 57000 to 58000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 58000 to 59000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 59000 to 60000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 60000 to 61000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 61000 to 62000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 62000 to 63000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 63000 to 64000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 64000 to 65000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 65000 to 66000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 66000 to 67000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 67000 to 68000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 68000 to 69000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 69000 to 70000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 70000 to 71000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 71000 to 72000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 72000 to 73000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 73000 to 74000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 74000 to 75000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 75000 to 76000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 76000 to 77000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 77000 to 78000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 78000 to 79000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 79000 to 80000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 80000 to 81000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 81000 to 82000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 82000 to 83000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 83000 to 84000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 84000 to 85000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 85000 to 86000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 86000 to 87000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 87000 to 88000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 88000 to 89000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 89000 to 90000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 90000 to 91000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 91000 to 92000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 92000 to 93000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 93000 to 94000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 94000 to 95000\n",
      "Computing new batch...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data to h5 for epoch 0 and indexes from 95000 to 96000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 96000 to 97000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 97000 to 98000\n",
      "Computing new batch...\n",
      "Writing data to h5 for epoch 0 and indexes from 98000 to 99000\n",
      "Computing new batch...\n",
      "end epoch\n",
      "Writing data to h5 for epoch 0 and indexes from 99000 to 100000\n",
      "Writing datasets to disk\n",
      "--- 35.59966683387756 seconds ---\n",
      "RMSE bruit moyen dist : 171.805\n"
     ]
    }
   ],
   "source": [
    "creation_input_RN(minimal_set_riken_location, minimal_set_prepared_input_location, minimal_set_labels_location, 1,\n",
    "                 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input and label sets for ../data/mini_set.h5 : \n",
      "Epoch 0...\n",
      "Computing new batch...\n",
      "end epoch\n",
      "Writing data to h5 for epoch 0 and indexes from 0 to 2\n",
      "Epoch 1...\n",
      "Computing new batch...\n",
      "end epoch\n",
      "Writing data to h5 for epoch 1 and indexes from 0 to 2\n",
      "Epoch 2...\n",
      "Computing new batch...\n",
      "end epoch\n",
      "Writing data to h5 for epoch 2 and indexes from 0 to 2\n",
      "Writing datasets to disk\n",
      "--- 0.009618997573852539 seconds ---\n",
      "RMSE bruit moyen dist : 175.68146\n"
     ]
    }
   ],
   "source": [
    "creation_input_RN(train_set_location, train_set_prepared_input_location, train_set_labels_location,\n",
    "                 3, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sortie \n",
    "\n",
    "    --- 4406.742647409439 seconds ---\n",
    "    RMSE bruit moyen dist : 171.77454\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_input_RN(test_set_location, test_set_prepared_input_location, test_set_labels_location,\n",
    "                 3, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sortie\n",
    "\n",
    "    --- 470.8216595649719 seconds ---\n",
    "    RMSE bruit moyen dist : 171.75496\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
