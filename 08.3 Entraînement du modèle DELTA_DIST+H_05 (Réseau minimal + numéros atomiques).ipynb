{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle DELTA_DIST+H_05 (Réseau minimal + numéros atomiques)\n",
    "\n",
    "L'entraînement des modèles précédents montre que la topologie des réseaux ne semble pas avoir une influence déterminante dans les performances. On a fait varier le nombre de couches cachées de 1 à 4, et la largueur des couches cachées de 1000 à 12000, et les performances ont toujours été sensiblement comparables. On a donc tendance à penser que l'on utilise des topologies trop complexes pour les tâches que nous tentons de réaliser.\n",
    "\n",
    "Nous allons donc entraîner ici un réseau de taille plus raisonnable par rapport à la tâche que nous effectuons, dans l'idée que cela nous fera gagner beaucoup de temps de calcul et que nous pourrons donc effectuer des recherches par quadrillage des meilleurs hyper-paramètres beaucoup plus importantes.\n",
    "\n",
    "Dans le même temps, nous avons dans l'idée qu'il manque peut-être aux réseaux l'information du numéro atomique des atomes pour effectuer des prédictions précises, le numéro atomique correspondant au nombre d'atomes d'hydrogène, qui ont une influence sur la géométrie de la molécule\n",
    "\n",
    "Nous allons donc travailler sur le jeu de données réduit du notebook 8.1, contenant les entrées préparées (positions + masses + numéros atomiques) et les sorties (delta distances) pour toutes les molécules de tailles comprises entre 2 et 60.\n",
    "\n",
    "Nous allons dans un premier temps entraîner un modèle avec des paramètres similaires à ceux utilisés dans les modèles précédents, puis analyser les résultats. \n",
    "\n",
    "Si les résultats sont identiques (une loss autour de 107), alors la réduction du jeu de données (notamment la suppression des données aberrantes), l'ajout des numéros atomiques et le travail sur un modèle contenant moins de connexions n'auront pas eu d'influence sur les résultats et nous allons pouvoir lancer des recherches par quadrillage beaucoup plus importantes des hyper-paramètres.\n",
    "\n",
    "Si les résultats du modèle sont meilleurs, alors nous allons tenter d'ajuster encore mieux les hyper-paramètres et de rechercher quel facteur a causé l'amélioration des résultats.\n",
    "\n",
    "Si les résultats du modèle sont pires, alors nous allons rechercher quel facteur a causé cette dégradation et l'ajuster.\n",
    "\n",
    "### Résultats\n",
    "\n",
    "Après avoir lancé l'entraînement du modèle sur 6e10 exemples (100 époques de 6 000 000 exemples), nous nous apercevons que les résultats sont très semblables aux modèles précédents, la losse stagne au bout de quelques batchs seulement autour de 106.8. Cela confirme que les modèles précédents étaient trop complexes. Nous avons donc l'avantage d'avoir un modèle beaucoup plus rapide à entraîner. Nous allons donc maintenant effectuer une recherche par quadrillage très importante des hyper-paramètres du modèle.\n",
    "\n",
    "\n",
    "#### Chemin des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared_input_loc = \"../data/train_set_riken_v2_prepared_input_bruit+_anums_reduced.h5\"\n",
    "train_labels_loc = \"../data/train_set_riken_v2_labels_bruit+_anums_reduced.h5\"\n",
    "\n",
    "mini_prepared_input_loc = \"../data/mini_set_prepared_input_bruit+_anums_reduced.h5\"\n",
    "mini_labels_loc = \"../data/mini_set_labels_bruit+_anums_reduced.h5\"\n",
    "\n",
    "models_loc = \"../models/DELTA_DIST+H_05/8.3/\"\n",
    "logs_loc = \"../models/DELTA_DIST+H_05/8.3/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du RN\n",
    "\n",
    "#### Fonction renvoyant le masque des atomes à prendre en compte pour les calculs\n",
    "\n",
    "L'entrée et la sortie du RN étant définies par une méthode de padding, seul un certain nombre d'entrées et de sortie est utilisé pour chaque exemple d'entraînement en fonction du nombre d'atomes de la molécule. On définit ici une fonction qui renvoie le masque des différences de distances à prendre en compte sur les données en entrée et les étiquettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etudiant/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/etudiant/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def calcul_masque_atomes_definis(targets):\n",
    "    \"\"\" On calcule le masque booléen des atomes donnés en entrée du RN en fonction du vecteur targets\"\"\"\n",
    "    \n",
    "    # On cherche à obtenir un masque booléen des atomes définis en entrée. Pour cela, on prend en entrée\n",
    "    # les étiquettes sous la forme d'une matrice (200, 4) dont chaque ligne i est la distance de l'atome i avec\n",
    "    # les atomes fictifs du repère. L'atome est indéfini ssi. la somme de la ligne est nulle. En effet,\n",
    "    # un atome défini ne peut pas avoir une distance nulle avec les quatre atomes fictifs, et on veille\n",
    "    # à ce que le vecteurs targets ne contienne que des valeurs nulles pour les atomes non définis.\n",
    "    # On obtient donc un masque booléen de tous les atomes définis en entrée\n",
    "    \n",
    "    ## On somme les distances de chaque atome ##\n",
    "    targets_dists_sums = tf.reduce_sum(targets, 1)\n",
    "    \n",
    "    ## On créé le masque des sommes différentes de zéro ##\n",
    "    \n",
    "    # Création des matrice de True et de False de la dimension de la matrice des sommes (nécessaires\n",
    "    # pour tf.where)\n",
    "    zeros = tf.cast(tf.zeros_like(targets_dists_sums),dtype=tf.bool)\n",
    "    ones = tf.cast(tf.ones_like(targets_dists_sums),dtype=tf.bool)\n",
    "    \n",
    "    return tf.where(targets_dists_sums>0, ones, zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de coût\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_rmse(predictions, targets):\n",
    "    \"\"\" Calcule le RMSE partiel des prédictions par rapport aux valeurs attendues. Le RMSE est partiel car\n",
    "    on ne le calcule que pour les sorties correspondant aux atomes donnés en entrée. En d'autres\n",
    "    termes, on ne pousse pas le modèle à donner des distances nulles pour les atomes indéfinis\n",
    "    en entrée\"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"partial_rmse\"):\n",
    "\n",
    "        # On met les prédictions et les cibles sous la forme d'une matrice (200, 4)\n",
    "        predictions = tf.reshape(predictions, [-1, 4])\n",
    "        targets = tf.reshape(targets, [-1, 4])\n",
    "\n",
    "        # On calcule le masque des atomes définis selon les cibles\n",
    "        defined_atoms_mask = calcul_masque_atomes_definis(targets)\n",
    "        \n",
    "        # On masque les prédictions et les étiquettes selon le masque des atomes définis\n",
    "        targets_masked = tf.boolean_mask(targets, defined_atoms_mask)\n",
    "        predictions_masked = tf.boolean_mask(predictions, defined_atoms_mask)\n",
    "        \n",
    "        sess = tf.InteractiveSession()\n",
    "\n",
    "        # Add print operation\n",
    "        predictions_masked = tf.Print(predictions_masked, [predictions_masked], message=\"Predictions :\")\n",
    "\n",
    "        return tf.sqrt(tf.reduce_mean(tf.squared_difference(predictions_masked, targets_masked)), name=\"rmse\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'évaluation des performances (score R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_r2_score(predictions, targets, inputs):\n",
    "    \"\"\" Renvoie le score R2 de la prédiction (le calcul est effectué uniquement sur les résultats\n",
    "    des atomes donnés en entrée) \"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"partial_r2\"):\n",
    "    \n",
    "        # On met les prédictions et les cibles sous la forme d'une matrice (200, 4)\n",
    "        predictions = tf.reshape(predictions, [-1, 4])\n",
    "        targets = tf.reshape(targets, [-1, 4])\n",
    "\n",
    "        # On calcule le masque des atomes définis selon les cibles\n",
    "        defined_atoms_mask = calcul_masque_atomes_definis(targets)\n",
    "\n",
    "        # On masque les prédictions et les étiquettes selon le masque des atomes définis\n",
    "        targets_masked = tf.boolean_mask(targets, defined_atoms_mask)\n",
    "        predictions_masked = tf.boolean_mask(predictions, defined_atoms_mask)\n",
    "\n",
    "        # Calcul de l'erreur totale\n",
    "        total_error = tf.reduce_sum(tf.square(tf.subtract(targets, tf.reduce_mean(targets_masked))))\n",
    "\n",
    "        # Calcul de l'erreur inexpliquée\n",
    "        unexplained_error = tf.reduce_sum(tf.square(tf.subtract(targets_masked, predictions_masked)))\n",
    "\n",
    "        r2 = tf.subtract(1.0, tf.divide(unexplained_error, total_error), \"r2_score\")\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition d'une fonction créant le RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etudiant/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/etudiant/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.optimizers import Adam\n",
    "from tflearn.data_preprocessing import DataPreprocessing\n",
    "import math\n",
    "\n",
    "\n",
    "def creer_360_x_240(epsilon=1e-8, learning_rate=0.001, dropout_val=0.99, stddev_init=0.001,\n",
    "                      hidden_act='relu', outlayer_act='prelu', weight_decay=0.001, width=360, depth=3):\n",
    "    \"\"\" Fonction créant un réseau de neurones de type fully connected, ayant une couche d'entrée de 360\n",
    "    neurones, quatre couches cachées de 360 neurones et une sortie de 240 neurones\n",
    "    Inputs : hyperparamètres\n",
    "    \"\"\"\n",
    "\n",
    "    # On créé l'initialisateur de tenseur avec une loi normale tronquée. sigma = stddev_init, et les \n",
    "    # valeurs à plus de 2sigma sont re-tirées\n",
    "    winit = tfl.initializations.truncated_normal(stddev=stddev_init, dtype=tf.float32, seed=None)\n",
    "    \n",
    "    # On créé l'input du RN\n",
    "    network = input_data(shape=[None, 360], name='input')\n",
    "    \n",
    "    # On créé les couches cachées\n",
    "    for i in range(depth):\n",
    "        network = fully_connected(network, width, activation=hidden_act, name='fc'+str(i), weights_init=winit,\n",
    "                                  weight_decay=weight_decay)\n",
    "        # On détruit des neurones aléatoirement avec une la probabilité donnée en entrée\n",
    "        network = dropout(network, dropout_val)\n",
    "    \n",
    "    # On ajoute la couche de sortie du réseau\n",
    "    # Fonction d'activation prelu\n",
    "    # Initilisée avec la loi normale tronquée\n",
    "    network = fully_connected(network, 240, activation=outlayer_act, name='outlayer', weights_init=winit)\n",
    "    \n",
    "    adam = Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
    "    \n",
    "    # Couche d'évaluation du modèle. Utilisation d'une descente stochastique Adam\n",
    "    # Learning rate = 0.05\n",
    "    # Loss = fonction définie rmse\n",
    "    network = regression(network, optimizer=adam,\n",
    "    loss=partial_rmse, metric=partial_r2_score, name='target')\n",
    "            \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "\n",
    "\n",
    "#### Fonction renvoyant deux sous-ensembles du jeu d'entrainement : un ensemble d'exemples et les cibles correspondantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(train_set, targets, reduce_train_fold_size):\n",
    "    \"\"\" Permet d'obtenir un sous-ensemble du jeu d'entraînement afin de ne pas travailler sur le jeu\n",
    "    d'entraînement total pour la recherche par quadrillage et donc de gagner du temps d'exécution. L'idée\n",
    "    et que si un ensemble d'hyper-paramètres produit des meilleurs résultats que les autres ensembles\n",
    "    d'hyper-paramètres sur l'ensemble du jeu d'entraînement, alors on suppose que ce sera également \n",
    "    le cas sur une partie des données. \"\"\"\n",
    "\n",
    "    return (train_set[\"inputs\"][:reduce_train_fold_size], targets[\"targets\"][:reduce_train_fold_size])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement des modèles\n",
    "\n",
    "#### Fonction d'entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tflearn as tfl\n",
    "import time\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def train_model(input_X, labels_y, model_name, model_path, logs_path, samples_per_batch=1000, epochs=5,\n",
    "                learning_rate=0.001, epsilon=1e-8, dropout=0.99, stddev_init=0.001, hidden_act='relu',\n",
    "                outlayer_act='prelu'):\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # On créé le réseau \n",
    "    network = creer_360_x_240(learning_rate=learning_rate, epsilon=epsilon, dropout_val=dropout,\n",
    "                                 stddev_init=stddev_init, hidden_act=hidden_act, outlayer_act=outlayer_act)\n",
    "\n",
    "    # On créé le modèle\n",
    "    model = tfl.DNN(network, tensorboard_verbose=3, tensorboard_dir=logs_path)\n",
    "\n",
    "    # Entraînement\n",
    "    model.fit(X_inputs=input_X,Y_targets=labels_y, batch_size=samples_per_batch,\n",
    "              shuffle = True, snapshot_step=100, validation_set=0.1,\n",
    "              show_metric=True, run_id=model_name, n_epoch=epochs)\n",
    "\n",
    "    # Sauvegarde du modèle\n",
    "    model.save(model_path + model_name + \".tflearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -63.81879   -60.495556  -27.063326 -124.909164  323.44885   311.92914\n",
      "  262.79605   353.49997  -200.99821   -53.761936 -329.13626  -172.72247\n",
      "  -83.03802  -144.36479  -189.3064    132.93494  -269.8073   -308.40668\n",
      " -224.28836  -269.59384    67.13267    65.626045   38.904064   94.60527\n",
      " -110.683586 -120.240555 -116.269165 -195.38763    43.11627   -45.85881\n",
      "   15.567158   13.33028  -103.34256  -116.60969   -67.16978   -73.85322\n",
      " -410.7601   -405.34308  -393.58395  -359.42197  -119.461395  -80.16686\n",
      " -136.78775   -80.40891    19.101686   22.287884  -75.83423    28.024733\n",
      "  -16.571526   -9.863982  -11.059247   19.688393  180.58093   180.54265\n",
      "  167.05176   184.57639   210.31181   181.68173   156.72606   199.78143\n",
      " -189.90836  -225.70856  -183.54733   -88.49711    28.604616   64.47135\n",
      "  -15.137252  -17.497793   21.275692   -7.958674   17.721409   39.20046\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.      ]\n",
      "[  11.888111     9.034711    39.08632      7.905122  -209.15254\n",
      " -220.34926   -134.73038   -251.34251     78.21553     69.12091\n",
      "   87.02292     82.211334  -260.49612   -244.78633   -225.8691\n",
      " -341.65503      5.494899    12.227887    11.2529335   -7.2656236\n",
      " -413.51978   -378.42908   -437.78683   -414.67767   -127.84287\n",
      " -180.68959    -60.68828   -130.37578     57.84239     54.997257\n",
      "   60.18221     56.826633   -38.084225   -31.761013   -60.481663\n",
      "  -28.186102  -122.66194   -112.08157   -133.87193   -127.135155\n",
      "  -98.763115   -98.53621    -97.21851    -91.26854   -150.49959\n",
      " -147.09964   -133.38542   -170.85114   -185.23836   -188.42537\n",
      " -187.49242   -162.13551     86.72183     71.01745     89.468414\n",
      "  117.07608     -5.675391    16.136007   -24.694233   -36.369102\n",
      "  -57.945515   -83.19035    -48.506397   -81.9535     549.9912\n",
      "  520.4381     491.1164     490.24826   -291.20193   -261.05478\n",
      " -346.42566   -276.24893   -126.45738    -62.733273   -19.014938\n",
      "  -56.877243  -282.33838   -202.37604   -242.38132   -192.7462\n",
      "  -40.317978   -11.167053   -49.07659    -61.417637   -88.45708\n",
      "  -45.77239   -123.45071    -65.25443    104.25665    140.12683\n",
      "   27.191       98.47115    111.04377    158.95264     71.07404\n",
      "   94.22308      0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.           0.       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etudiant/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: DELTA_DIST+H_05_basic\n",
      "Log directory: ../models/DELTA_DIST+H_05/8.3/\n",
      "INFO:tensorflow:Summary name partial_r2/ (raw) is illegal; using partial_r2/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 1\n",
      "--\n",
      "Training Step: 1  | time: 1.452s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - partial_r2/r2_score: 0.0000 | val_loss: 195.43549 - val_acc: 0.8524 -- iter: 1/1\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "input_X_h5 = h5py.File(train_prepared_input_loc, 'r')\n",
    "labels_y_h5 = h5py.File(train_labels_loc, 'r')\n",
    "\n",
    "\"\"\"\n",
    "input_X_h5 = h5py.File(mini_prepared_input_loc, 'r')\n",
    "labels_y_h5 = h5py.File(mini_labels_loc, 'r')\n",
    "\n",
    "\"\"\"\n",
    "input_X, labels_y = get_fold(input_X_h5, labels_y_h5, 2500000)\n",
    "\n",
    "model_name = \"DELTA_DIST+H_05_basic\"\n",
    "model_path = models_loc\n",
    "logs_path = logs_loc\n",
    "\n",
    "train_model(input_X, labels_y, model_name, model_path, logs_path, samples_per_batch=10000, \n",
    "            epochs=5, learning_rate=0.01, dropout=0.97, epsilon=0.001, hidden_act=\"relu6\",\n",
    "            outlayer_act=\"linear\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
