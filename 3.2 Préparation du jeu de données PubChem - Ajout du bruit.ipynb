{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation du jeu de données PubChem - Ajout du bruit (Tesla)\n",
    "\n",
    "Dans ce notebook, on va définir les fonctions créant les fichiers de données qui seront utilisées pour l'entraînement et la validation du modèle (coordonnées bruitées et labels de différences de distances attendues)\n",
    "\n",
    "On définit pour cela une fonction prenant les chemins du jeu à préparer et le chemin de deux fichiers h5 à créer : le jeu contenant les entrées du RN pour tous les exemples (un tableau de 1000 floats par molécule contenant les distances des atomes au repère et leurs masses), et le jeu contenant les cibles (un tableau de 800 floats par molécule contenant les delta distances à calculer en mÅ)\n",
    "\n",
    "Cette solution de créer des fichiers de données préparées plutôt que de préparer les données en mémoire durant l'apprentissage par le RN va faciliter l'écriture du code d'entraînement du RN et permet de tester plus facilement les différentes étapes indépendantes de l'entraînement du modèle, mais elle possède l'inconvénient de créér des fichiers très volumineux. La base de données actuelle étant de taille raisonnable et 3To de disque étant disponibles, les limites ne sont pas atteintes actuellement, mais il faudrait passer à une solution de préparation des données dynamique lors de l'apprentissage si l'on souhaite entraîner un modèle à partir de milliards d'exemples par la suite. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des chemins de fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_location = \"../data/test_set_riken_v2.h5\"\n",
    "test_set_prepared_input_location = \"../data/test_set_riken_v2_prepared_input.h2\"\n",
    "test_set_labels_location = \"../data/test_set_riken_v2_labels.h2\"\n",
    "\n",
    "train_set_location = \"../data/train_set_riken_v2.h5\"\n",
    "train_set_prepared_input_location = \"../data/train_set_riken_v2_prepared_input.h5\"\n",
    "train_set_labels_location = \"../data/train_set_riken_v2_labels.h5\"\n",
    "\n",
    "minimal_set_riken_location = \"../data/minimal_set_riken_v2.h5\"\n",
    "minimal_set_prepared_input_location = \"../data/minimal_set_riken_v2_prepared_input.h5\"\n",
    "minimal_set_labels_location = \"../data/minimal_set_riken_v2_labels.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction d'ajout de bruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def positions_bruitees(positions):    \n",
    "    bruit = np.random.normal(loc=0.0, scale=0.028867, size=positions.shape)\n",
    "    return ((positions + bruit), bruit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction de calcul de la matrice de distances compressée à partir de la matrice des coordonnées des atomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_distances_compr(positions):\n",
    "    \"\"\" Renvoie la matrice de distances compressée des positions des atomes passées en paramètres\n",
    "    La matrice de distances compressée est définie de la façon suivante : pour chaque atome, on calcule\n",
    "    la distance avec chaque point du repère. Une ligne i de la matrice (n,4) correspond aux distances\n",
    "    de l'atome i avec chacun des quatre points du repère\"\"\"\n",
    "    \n",
    "    nb_at = len(positions)\n",
    "    \n",
    "    # On renvoie un tableau vide si la molécule est vide\n",
    "    if nb_at == 0:\n",
    "        return []\n",
    "    \n",
    "    repere = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    repere = np.vstack([repere]*nb_at)\n",
    "\n",
    "    positions = np.tile(positions, 4).reshape(4*nb_at, 3)\n",
    "    \n",
    "    return np.sqrt(np.sum(np.power(positions-repere, 2), 1)).reshape(nb_at, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de la fonction de création des fichiers h5 de données et de labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def creation_input_RN(set_location, input_rn_location, labels_location):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    mol_vides = 0\n",
    "    \n",
    "    print(\"Creating input and label sets for \"+set_location+\" : \")\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    # On charge le jeu de données original (en lecture seule)\n",
    "    original_dataset_h5 = h5py.File(set_location, 'r')\n",
    "    \n",
    "    # On enregistre la taille du jeu de données\n",
    "    taille = len(original_dataset_h5[\"anums\"])\n",
    "        \n",
    "    # On créé les jeu deux données d'entrée du RN et de labels\n",
    "    input_rn_dataset_h5 = h5py.File(input_rn_location, 'w')\n",
    "    labels_dataset_h5 = h5py.File(labels_location, 'w')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "    \n",
    "        # Définition du type pour les tableaux de floats\n",
    "        varlen_floatarray = h5py.special_dtype(vlen=np.dtype(\"float32\"))\n",
    "\n",
    "        print(\"Creating new files...\")\n",
    "        # On créé les datasets input et target\n",
    "        input_dataset = input_rn_dataset_h5.create_dataset(\"inputs\", shape=(taille,),\n",
    "                                           dtype=varlen_floatarray, compression=\"gzip\", \n",
    "                                           chunks=True, maxshape=(None,))\n",
    "\n",
    "        targets_dataset = labels_dataset_h5.create_dataset(\"targets\", shape=(taille,),\n",
    "                                           dtype=varlen_floatarray, compression=\"gzip\", \n",
    "                                           chunks=True, maxshape=(None,))\n",
    "\n",
    "\n",
    "        print(\"Computing input and label sets...\")\n",
    "        # On parcourt toutes les molécules de l'exemple\n",
    "        for i in range(taille):\n",
    "\n",
    "            if i%10000 == 0:\n",
    "                print(\"Computing input and label sets for molecule \"+str(i)+\" (\"+str(i/taille*100)+\"%)\")\n",
    "\n",
    "            # On récupère les coordonnées de la molécule courante et on y ajoute du bruit\n",
    "            coords = np.array(original_dataset_h5[\"riken_coords\"][i]).reshape(-1,3)\n",
    "            dist_init = matrice_distances_compr(coords)\n",
    "            coords_bruit, bruit = positions_bruitees(coords)\n",
    "            coords_bruit = coords_bruit.reshape(-1, 3)\n",
    "            bruit = bruit.reshape(-1, 3)\n",
    "            \n",
    "            if len(coords) == 0:\n",
    "                print(\"Molécule vide\")\n",
    "                mol_vides += 1\n",
    "            else:\n",
    "                # On calcule les différence de distances cibles (en mÅ) et les distances bruitées (en Å)\n",
    "                dist_bruit = matrice_distances_compr(coords_bruit)\n",
    "                delta_dist_targets = (dist_init - dist_bruit)*1000\n",
    "\n",
    "            # On récupère les masses atomiques de la molécule courante\n",
    "            masses = original_dataset_h5[\"amasses\"][i]\n",
    "\n",
    "            # On initialise l'entrée du RN et le vecteur cible pour la molécule courante\n",
    "            entree_courante = np.zeros(shape=(1000, 1))\n",
    "            cible_courante = np.zeros(shape=(200, 4))\n",
    "\n",
    "            # On ajoute les coordonnées bruitées et les masses à l'entrée avec padding, et les coordonnées\n",
    "            # cibles au dataset targets\n",
    "            j=0\n",
    "            for masse in masses:\n",
    "                \n",
    "                # Ajout des données au vecteur entrée\n",
    "                index_input_courant = j*5\n",
    "                entree_courante[index_input_courant] = dist_bruit[j][0]\n",
    "                entree_courante[index_input_courant+1] = dist_bruit[j][1]\n",
    "                entree_courante[index_input_courant+2] = dist_bruit[j][2]\n",
    "                entree_courante[index_input_courant+3] = dist_bruit[j][3]\n",
    "                entree_courante[index_input_courant+4] = masse\n",
    "                \n",
    "                # Ajout des données à la matrice cibles\n",
    "                cible_courante[j] = delta_dist_targets[j]\n",
    "\n",
    "                j+=1\n",
    "\n",
    "            # On aplatit le vecteur cibles\n",
    "            cible_courante = cible_courante.reshape(1, 800)\n",
    "            \n",
    "            # On insère les données dans le fichier h5 en mémoire\n",
    "            input_dataset[i] = entree_courante.reshape(-1, 1000)\n",
    "            targets_dataset[i] = cible_courante\n",
    "\n",
    "        print(\"Writing datasets on disk...\")\n",
    "        # On écrit les datasets sur le disque\n",
    "        input_rn_dataset_h5.flush()\n",
    "        labels_dataset_h5.flush()\n",
    "        \n",
    "        print(str(mol_vides)+\" molécules vides au total\")\n",
    "\n",
    "\n",
    "        print(input_rn_location+\" and \"+labels_location+\" have been correctly written on disk\")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "    finally:\n",
    "        original_dataset_h5.close()\n",
    "        input_rn_dataset_h5.close()\n",
    "        labels_dataset_h5.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des données d'entrée du RN et des labels pour le jeu minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Préparation données jeu minimal :\n",
      "Creating input and label sets for ../data/minimal_set_riken_v2.h5 : \n",
      "Loading data...\n",
      "Creating new files...\n",
      "Computing input and label sets...\n",
      "Computing input and label sets for molecule 0 (0.0%)\n",
      "Computing input and label sets for molecule 10000 (10.0%)\n",
      "Computing input and label sets for molecule 20000 (20.0%)\n",
      "Computing input and label sets for molecule 30000 (30.0%)\n",
      "Computing input and label sets for molecule 40000 (40.0%)\n",
      "Computing input and label sets for molecule 50000 (50.0%)\n",
      "Computing input and label sets for molecule 60000 (60.0%)\n",
      "Computing input and label sets for molecule 70000 (70.0%)\n",
      "Computing input and label sets for molecule 80000 (80.0%)\n",
      "Computing input and label sets for molecule 90000 (90.0%)\n",
      "Writing datasets on disk...\n",
      "0 molécules vides au total\n",
      "../data/minimal_set_riken_v2_prepared_input.h5 and ../data/minimal_set_riken_v2_labels.h5 have been correctly written on disk\n",
      "--- 138.18809986114502 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Préparation données jeu minimal :\")\n",
    "creation_input_RN(minimal_set_riken_location, minimal_set_prepared_input_location,\n",
    "                  minimal_set_labels_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des données d'entrée du RN et des labels pour le jeu d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Préparation données jeu d'entraînement :\")\n",
    "creation_input_RN(train_set_location, train_set_prepared_input_location, train_set_labels_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des données d'entrée du RN et des labels pour le jeu de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Préparation données jeu de validation :\")\n",
    "creation_input_RN(test_set_location, test_set_prepared_input_location, test_set_labels_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time : \n",
      "--- 138.90174651145935 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Total time : \")\n",
    "print(\"--- %s seconds ---\" % (time.time() - total_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
